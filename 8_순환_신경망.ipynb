{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8. 순환 신경망",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXML4e8Dv+XJxTyKFg0foM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1) 순환 신경망\n",
        "## 2. 케라스로 RNN 구현하기"
      ],
      "metadata": {
        "id": "6iMg4E4Wt2av"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "rIvIJR4QtzfK",
        "outputId": "592ca820-544a-4b5f-805a-1961c97dffc9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-741e5ebe1c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'hidden_units' is not defined"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import SimpleRNN\n",
        "\n",
        "# 책에선 없지만 없으면 model 안됨\n",
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(hidden_units))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 추가 인자를 사용할 때\n",
        "model.add(SimpleRNN(hidden_units, input_shape=(timesteps, input_dim)))\n",
        "\n",
        "# 다른 표기\n",
        "model.add(SimpleRNN(hidden_units, input_length=M, input_dim=N))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "3g7jIOPpuCMK",
        "outputId": "10c351d4-cdee-437d-ad4d-4c2bd7073f88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-887ced775d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 추가 인자를 사용할 때\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 다른 표기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hidden_units' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, input_shape=(2,10)))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzsyae89x2Hi",
        "outputId": "4123a40a-b617-4a9c-bd07-e26e7cfc0e68"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 3)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size 정의\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10)))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzNxPgNA0j5O",
        "outputId": "71a09741-de07-4ba7-899b-3490812b07b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (8, 3)                    42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 파이썬으로 RNN 구현하기"
      ],
      "metadata": {
        "id": "-QMpCsQA099B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 은닉 상태 출력\n",
        "import numpy as np\n",
        "\n",
        "timesteps = 10\n",
        "input_dim = 4\n",
        "hidden_units = 8    # 은닉 상태의 크기를 8로 지정하였으므로 8의 차원을 가지는 0의 값으로 구성된 벡터 출력\n",
        "\n",
        "# 입력에 해당되는 2D 텐서\n",
        "inputs = np.random.random((timesteps, input_dim))\n",
        "\n",
        "# 초기 은닉 상태는 0(벡터)로 초기화\n",
        "hidden_state_t = np.zeros((hidden_units,))\n",
        "\n",
        "print('초기 은닉 상태 :', hidden_state_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMGPw--y012T",
        "outputId": "b1d8ad34-f2b5-4785-a9a5-ec1c6309846a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "초기 은닉 상태 : [0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치와 편향을 각 크기에 맞게 정의하고 크기를 출력\n",
        "Wx = np.random.random((hidden_units, input_dim))    # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치\n",
        "Wh = np.random.random((hidden_units, hidden_units))    #(8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치\n",
        "b = np.random.random((hidden_units,))    # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)\n",
        "\n",
        "print(\"가중치 Wx의 크기(shape) :\", np.shape(Wx))\n",
        "print(\"가중치 Wh의 크기(shape) :\", np.shape(Wh))\n",
        "print(\"편향의 크기(shape) :\", np.shape(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpTaDpfI1vVx",
        "outputId": "3343a64e-f8ff-497d-a765-9731b7ec8854"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가중치 Wx의 크기(shape) : (8, 4)\n",
            "가중치 Wh의 크기(shape) : (8, 8)\n",
            "편향의 크기(shape) : (8,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_hidden_states = []\n",
        "\n",
        "# 각 시점 별 입력값\n",
        "for input_t in inputs:\n",
        "\n",
        "  # Wx * Xt + Wh * Ht-1 + b(bias)\n",
        "  output_t = np.tanh(np.dot(Wx, input_t) + np.dot(Wh, hidden_state_t) + b)\n",
        "\n",
        "  # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep t, output_dim)\n",
        "  # 각 시점의 은닉 상태의 값을 계속해서 누적\n",
        "  total_hidden_states.append(list(output_t))\n",
        "  hidden_state_t = output_t\n",
        "\n",
        "# 출력 시 값을 깔끔하게 해주는 용도\n",
        "total_hidden_states = np.stack(total_hidden_states, axis = 0)\n",
        "\n",
        "# (timesteps, output_dim)\n",
        "print(\"모든 시점의 은닉 상태 :\")\n",
        "print(total_hidden_states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN0WpPxg2ig4",
        "outputId": "d728a1b3-a4d1-4c0e-9bd7-5e7610bf3127"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모든 시점의 은닉 상태 :\n",
            "[[0.85892501 0.73176634 0.5251392  0.89855182 0.80492195 0.55550789\n",
            "  0.95886989 0.94872285]\n",
            " [0.99958636 0.99737525 0.99843232 0.99994022 0.9995729  0.99958485\n",
            "  0.99978895 0.99989431]\n",
            " [0.99993836 0.99965306 0.99990156 0.99999652 0.99998131 0.99993636\n",
            "  0.99998939 0.99998785]\n",
            " [0.99979967 0.99896374 0.99961893 0.99997422 0.99950914 0.99984453\n",
            "  0.99995005 0.99997152]\n",
            " [0.99979573 0.99878326 0.9993622  0.99997098 0.99938293 0.99987047\n",
            "  0.99994438 0.99997303]\n",
            " [0.9998951  0.99919469 0.99971106 0.99998333 0.99977733 0.99990134\n",
            "  0.99998262 0.99998682]\n",
            " [0.99995261 0.99930951 0.99983762 0.99998804 0.99991495 0.99993583\n",
            "  0.99999148 0.99999357]\n",
            " [0.99989408 0.99958168 0.99983894 0.99999529 0.99996173 0.99991781\n",
            "  0.99997969 0.99997959]\n",
            " [0.99991443 0.99957662 0.9998786  0.9999931  0.99993164 0.99990308\n",
            "  0.99999216 0.99998852]\n",
            " [0.99981444 0.99908011 0.9994009  0.99998702 0.99982257 0.99990953\n",
            "  0.99991842 0.99996495]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 깊은 순환 신경망"
      ],
      "metadata": {
        "id": "rJ4b7qR44AVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 은닉층을 2개 추가하는 경우의 코드\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(hidden_units, input_length=10, input_dim=5, return_sequences=True))\n",
        "model.add(SimpleRNN(hidden_units, return_sequences=True))"
      ],
      "metadata": {
        "id": "mtSUG8xk3Rf9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 양방향 순환 신경망"
      ],
      "metadata": {
        "id": "HsgYLeZ-5cs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞 시점의 은닉상태와 뒤 시점의 은닉 상태의 값 모두가 현재 시점의 출력층에서 출력값을 예측하기 위해 사용\n",
        "from tensorflow.keras.models import Bidirectional\n",
        "\n",
        "timesteps = 10\n",
        "input_dim = 5\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "58XbJUa64UTj",
        "outputId": "5175ffe6-bd29-496b-8cd7-fa5f65e74732"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-db1b5d4cc481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 앞 시점의 은닉상태와 뒤 시점의 은닉 상태의 값 모두가 현재 시점의 출력층에서 출력값을 예측하기 위해 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Bidirectional' from 'tensorflow.keras.models' (/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/models/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) 케라스의 SimpleRNN과 LSTM 이해하기\n",
        "## 1. 임의의 입력 생성하기"
      ],
      "metadata": {
        "id": "iCXEppyx-k1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional"
      ],
      "metadata": {
        "id": "ufXBQNE354rm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN과 LSTM을 테스트하기 위한 임의의 입력\n",
        "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
        "print(np.shape(train_X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlOHgt5i-y9J",
        "outputId": "7d637ff9-9ae3-4d48-ada6-20d568e0c600"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D 텐서를 3D 텐서로 변경\n",
        "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
        "train_X = np.array(train_X, dtype=np.float32)\n",
        "print(train_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MJTgQE0-9BT",
        "outputId": "5313fc41-2002-489c-8e9e-020acfdb5650"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimpleRNN 이해하기"
      ],
      "metadata": {
        "id": "wx-44Hp5Am-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 은닉 상태의 크기3, 두 인자 값이 모두 False일 때의 출력값\n",
        "rnn = SimpleRNN(3)\n",
        "# rnn = SimpleRNN(3, return_sequences=False, return_state=False)와 동일\n",
        "hidden_state = rnn(train_X)\n",
        "\n",
        "print(\"hidden state : {}, shape : {}\".format(hidden_state, hidden_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLNWh5aVAO_9",
        "outputId": "a8559b4f-cbe7-48f8-b66a-eeb342be4d24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state : [[ 0.92126375 -0.9438475  -0.9928897 ]], shape : (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return_sequences를 True로 지정하여 모든 시점의 은닉 상태를 출력\n",
        "rnn = SimpleRNN(3, return_sequences=True)\n",
        "hidden_states = rnn(train_X)\n",
        "\n",
        "print(\"hidden states : {}, shape : {}\".format(hidden_states, hidden_states.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f2D7LT1BDfh",
        "outputId": "7ae1b183-1c94-438c-a07e-a0f6e17c8362"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[[ 0.9833128   0.9935881  -0.9993068 ]\n",
            "  [ 0.85626465  0.99619716 -0.9940144 ]\n",
            "  [-0.02891342  0.1666882  -0.925371  ]\n",
            "  [-0.6240324   0.92511374 -0.93153566]]], shape : (1, 4, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return_state가 True일 경우에는 return_sequences의 True/False 여부와 상관없이 마지막 시점의 은닉 상태를 출력\n",
        "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
        "hidden_states, last_state = rnn(train_X)\n",
        "\n",
        "print(\"hidden states : {}, shape : {}\".format(hidden_states, hidden_states.shape))\n",
        "print(\"last hidden state : {}, shape : {}\".format(last_state, last_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1kyRo1uBtj-",
        "outputId": "1b0ccb02-324d-48e4-8cab-1df0f2d20a1a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[[-0.21191558  0.9247593  -0.5584665 ]\n",
            "  [-0.16361693  0.78625154 -0.96553063]\n",
            "  [ 0.2464614   0.21260898 -0.97729856]\n",
            "  [ 0.5551516   0.98431927 -0.49670163]]], shape : (1, 4, 3)\n",
            "last hidden state : [[ 0.5551516   0.98431927 -0.49670163]], shape : (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return_sequences는 False, return_state는 True인 경우\n",
        "# 두 개의 출력 모두 마지막 시점의 은닉 상태를 출력\n",
        "rnn = SimpleRNN(3, return_sequences=False, return_state=True)\n",
        "hidden_state, last_state = rnn(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxQyhAnSCVEW",
        "outputId": "6bd315ac-e403-48ea-c2f2-7d0da62610f6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state : [[ 0.9712757  -0.9757286   0.04037877]], shape: (1, 3)\n",
            "last hidden state : [[ 0.9712757  -0.9757286   0.04037877]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM 이해하기"
      ],
      "metadata": {
        "id": "CD_3mmXIDb1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 입력에 대해서 LSTM을 사용할 경우\n",
        "lstm = LSTM(3, return_sequences=False, return_state=True)\n",
        "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))\n",
        "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDOVPuDPDT8d",
        "outputId": "2f677451-39dc-401c-ee14-8d70dc265b50"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state : [[-0.12563483 -0.30545184  0.09709059]], shape: (1, 3)\n",
            "last hidden state : [[-0.12563483 -0.30545184  0.09709059]], shape: (1, 3)\n",
            "last cell state : [[-0.65726584 -1.1308584   0.24708945]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM은 return_state를 True로 둔 경우에는 마지막 시점의 은닉 상태뿐만 아니라 셀 상태까지 반환\n",
        "# return_sequences = True\n",
        "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
        "hidden_states, last_hidden_state, last_cell_state = lstm(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_hidden_state, last_hidden_state.shape))\n",
        "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwqYxRNtDscn",
        "outputId": "faf10c05-3dc4-48ae-d4ba-3bdc7862af6a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[[ 2.9361385e-01 -7.8314334e-02  6.8932626e-04]\n",
            "  [ 3.1340003e-01 -4.3612391e-01 -3.3691153e-04]\n",
            "  [ 4.2513573e-01 -5.2452689e-01  4.2103127e-02]\n",
            "  [ 4.2195633e-01 -5.5606651e-01  4.5449071e-02]]], shape: (1, 4, 3)\n",
            "last hidden state : [[ 0.42195633 -0.5560665   0.04544907]], shape: (1, 3)\n",
            "last cell state : [[ 0.642616   -2.176991    0.06499276]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Bidirectional(LSTM) 이해하기"
      ],
      "metadata": {
        "id": "FC40mL4XEMAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_init = tf.keras.initializers.Constant(value=0.1)\n",
        "b_init = tf.keras.initializers.Constant(value=0)\n",
        "r_init = tf.keras.initializers.Constant(value=0.1)"
      ],
      "metadata": {
        "id": "b7MRkqmyEGCt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return_sequences가 False이고, return_state가 True인 경우\n",
        "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, \\\n",
        "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
        "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
        "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2TcyzKrEeqy",
        "outputId": "c0712b9d-4f5f-4cf5-db04-3d57af6e88f4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[0.63031393 0.63031393 0.63031393 0.7038734  0.7038734  0.7038734 ]], shape: (1, 6)\n",
            "forward state : [[0.63031393 0.63031393 0.63031393]], shape: (1, 3)\n",
            "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 은닉 상태의 값을 고정시켜두었기 때문에 return_sequences를 True로 할 경우, 출력이 어떻게 바뀌는지 비교 가능\n",
        "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True, \\\n",
        "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
        "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
        "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxhmJG8IFChS",
        "outputId": "6a906243-4f4d-464b-8498-9273debdba5b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden states : [[[0.35906473 0.35906473 0.35906473 0.7038734  0.7038734  0.7038734 ]\n",
            "  [0.5511133  0.5511133  0.5511133  0.58863586 0.58863586 0.58863586]\n",
            "  [0.59115744 0.59115744 0.59115744 0.3951699  0.3951699  0.3951699 ]\n",
            "  [0.63031393 0.63031393 0.63031393 0.21942244 0.21942244 0.21942244]]], shape: (1, 4, 6)\n",
            "forward state : [[0.63031393 0.63031393 0.63031393]], shape: (1, 3)\n",
            "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) RNN을 이용한 텍스트 생성\n",
        "## 1. RNN을 이용하여 택스트 생성하기\n",
        "### 1) 데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "uCfUzGecF_7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "HESZ_7G-Fkf4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 집합을 생성하고 크기 확인\n",
        "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"단어 집합의 크기 : %d\" % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TtJNv1YGbSu",
        "outputId": "4b9b9e4e-f68b-4184-a1a9-78e3fb737d87"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 단어와 단어에 부여된 정수 인덱스 출력\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ahvpsYGwmX",
        "outputId": "fe53cd04-192f-476c-f857-38e7197d6a7f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 작성\n",
        "sequences = list()\n",
        "for line in text.split('\\n'):    # 줄바꿈 문자를 기준으로 문장 토큰화\n",
        "  encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(encoded)):\n",
        "    sequence = encoded[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "print(\"학습에 사용할 샘플의 개수 : %d\" %len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCHOhfeeG17w",
        "outputId": "4775b0da-b098-413c-a381-c14eed9b2b6c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습에 사용할 샘플의 개수 : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 샘플 출력\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIwEBWabHO2r",
        "outputId": "22131ae0-a9e4-470c-b986-a05cf07a37f0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 긴 샘플을 기준으로 전체 샘플의 길이 일치시키기\n",
        "max_len = max(len(l) for l in sequences)    # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
        "print(\"샘플의 최대 길이 : {}\".format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJOTSLwTHTIp",
        "outputId": "b6d215ad-beb8-4ead-f4f4-bff371a9e5a5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 긴 샘플의 길이로 패딩\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "MOPXJ-jDIYeb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3IzvQw8Ige7",
        "outputId": "0a4ed6d9-0712-4c81-c709-0bea277d4e7a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2  3]\n",
            " [ 0  0  0  2  3  1]\n",
            " [ 0  0  2  3  1  4]\n",
            " [ 0  2  3  1  4  5]\n",
            " [ 0  0  0  0  6  1]\n",
            " [ 0  0  0  6  1  7]\n",
            " [ 0  0  0  0  8  1]\n",
            " [ 0  0  0  8  1  9]\n",
            " [ 0  0  8  1  9 10]\n",
            " [ 0  8  1  9 10  1]\n",
            " [ 8  1  9 10  1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 샘플의 마지막 단어를 레이블로 분리\n",
        "sequences = np.array(sequences)\n",
        "x = sequences[:, :-1]     # 리스트의 마지막 값을 제외하고 저장\n",
        "y = sequences[:, -1]    # 리스트의 마지막 값만 저장\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVWWeug2Il6a",
        "outputId": "42aec961-0791-4016-e987-4dd08c5128fb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n",
            "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블에 대해서 원-핫 인코딩 수행\n",
        "y = to_categorical(y, num_classes = vocab_size)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5w_LT6sI-zb",
        "outputId": "b5dd1a3b-2414-42ef-e03e-e2f889143a50"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 모델 설계하기"
      ],
      "metadata": {
        "id": "imYRcI56JKud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
      ],
      "metadata": {
        "id": "JztQXfFFJH4l"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10\n",
        "hidden_units = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH-F_9jxJVvX",
        "outputId": "afe87b1c-5194-48c5-e83a-93b915c40593"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 1s - loss: 2.4750 - accuracy: 0.0909 - 1s/epoch - 1s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 2.4625 - accuracy: 0.0909 - 9ms/epoch - 9ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 2.4498 - accuracy: 0.0909 - 7ms/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 2.4369 - accuracy: 0.0909 - 5ms/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 2.4237 - accuracy: 0.0909 - 5ms/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.4101 - accuracy: 0.1818 - 6ms/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.3959 - accuracy: 0.0909 - 8ms/epoch - 8ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.3812 - accuracy: 0.1818 - 8ms/epoch - 8ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.3659 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 2.3498 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.3329 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.3152 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.2967 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.2773 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.2569 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.2357 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.2136 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.1907 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.1671 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.1430 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.1185 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.0938 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.0693 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 2.0451 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 2.0216 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 1.9991 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 1.9778 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 1.9579 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 1.9395 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 1.9226 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 1.9072 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 1.8930 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 1.8797 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.8671 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.8548 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.8425 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.8301 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.8173 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.8041 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.7905 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.7764 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.7620 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.7473 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.7324 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.7173 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.7022 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.6869 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.6715 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.6561 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.6404 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.6246 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.6086 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.5922 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.5756 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.5586 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.5411 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.5234 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.5052 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.4867 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.4679 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.4489 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.4297 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.4104 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.3910 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.3716 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.3522 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.3328 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.3134 - accuracy: 0.6364 - 6ms/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.2942 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.2751 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.2560 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.2371 - accuracy: 0.6364 - 6ms/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.2183 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.1997 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.1812 - accuracy: 0.6364 - 6ms/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.1628 - accuracy: 0.6364 - 6ms/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 1.1446 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 1.1266 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 1.1087 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 1.0910 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 1.0735 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 1.0562 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 1.0390 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 1.0220 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 1.0052 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.9886 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.9722 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.9559 - accuracy: 0.7273 - 12ms/epoch - 12ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.9399 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.9240 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.9084 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.8929 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.8777 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.8626 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.8478 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.8331 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.8187 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.8044 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.7903 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.7764 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.7627 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.7492 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.7358 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.7226 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.7095 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.6966 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.6839 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.6713 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.6589 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.6466 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.6345 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.6226 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.6108 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.5991 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.5877 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.5764 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.5653 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.5543 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.5436 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.5330 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.5226 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.5124 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.5024 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.4926 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.4829 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.4735 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.4643 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.4552 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.4464 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.4377 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.4292 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.4209 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.4128 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.4049 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.3971 - accuracy: 0.9091 - 13ms/epoch - 13ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.3895 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.3821 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.3749 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.3678 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.3609 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.3541 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.3475 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.3410 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.3347 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.3285 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.3224 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.3165 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.3107 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.3050 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.2994 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.2940 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2886 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2834 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2782 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2732 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2683 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2634 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2587 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2540 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2495 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2450 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.2406 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.2362 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.2320 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.2278 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.2237 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.2196 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.2156 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.2117 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.2079 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.2041 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.2004 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1967 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1931 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1896 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1861 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1826 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1792 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1759 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1726 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1694 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1662 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1631 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1601 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1571 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1541 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1512 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1483 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1455 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1427 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.1400 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.1374 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.1348 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.1322 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.1297 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.1272 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.1248 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.1224 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.1201 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.1178 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcfef2786d0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델이 정확하게 예측하고 있는지 문장을 생성하는 함수\n",
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
        "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "6RaDGRlVJyjg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, \"경마장에\", 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9KLpfOuK0mn",
        "outputId": "3f1eeb1d-00c7-48aa-d3d8-6d557cbeeb3d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경마장에 있는 말이 뛰고 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '그의', 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KprzdLNVK766",
        "outputId": "da921084-bb1a-4627-b405-1221a8f7cf49"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그의 말이 법이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '가는', 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8KOi1ocLBQ7",
        "outputId": "89776382-fb3d-4855-df60-e96f79029311"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가는 말이 고와야 오는 말이 곱다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. LSTM을 이용하여 텍스트 생성하기\n",
        "### 1) 데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "_DnddIvoYcRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Md_B_Q80LD1T"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/ArticlesApril2018.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "T35SwrOsZShq",
        "outputId": "8c25cd4f-9f78-4a3d-bd5d-7d1f99f3e8e6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ca104fee-0de5-412f-89f0-fd625c0d65fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5adf6684068401528a2aa69b</td>\n",
              "      <td>781</td>\n",
              "      <td>By JOHN BRANCH</td>\n",
              "      <td>article</td>\n",
              "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
              "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
              "      <td>68</td>\n",
              "      <td>Sports</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:16:49</td>\n",
              "      <td>Pro Football</td>\n",
              "      <td>“I understand that they could meet with us, pa...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5adf653f068401528a2aa697</td>\n",
              "      <td>656</td>\n",
              "      <td>By LISA FRIEDMAN</td>\n",
              "      <td>article</td>\n",
              "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
              "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
              "      <td>68</td>\n",
              "      <td>Climate</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:11:21</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>The agency plans to publish a new regulation T...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5adf4626068401528a2aa628</td>\n",
              "      <td>2427</td>\n",
              "      <td>By PETE WELLS</td>\n",
              "      <td>article</td>\n",
              "      <td>The New Noma, Explained</td>\n",
              "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
              "      <td>66</td>\n",
              "      <td>Dining</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:58:44</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>What’s it like to eat at the second incarnatio...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5adf40d2068401528a2aa619</td>\n",
              "      <td>626</td>\n",
              "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
              "      <td>68</td>\n",
              "      <td>Washington</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:35:57</td>\n",
              "      <td>Europe</td>\n",
              "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5adf3d64068401528a2aa60f</td>\n",
              "      <td>815</td>\n",
              "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
              "      <td>68</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:21:21</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca104fee-0de5-412f-89f0-fd625c0d65fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca104fee-0de5-412f-89f0-fd625c0d65fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca104fee-0de5-412f-89f0-fd625c0d65fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  articleID  ...                                             webURL\n",
              "0  5adf6684068401528a2aa69b  ...  https://www.nytimes.com/2018/04/24/sports/foot...\n",
              "1  5adf653f068401528a2aa697  ...  https://www.nytimes.com/2018/04/24/climate/epa...\n",
              "2  5adf4626068401528a2aa628  ...  https://www.nytimes.com/2018/04/24/dining/noma...\n",
              "3  5adf40d2068401528a2aa619  ...  https://www.nytimes.com/2018/04/24/world/europ...\n",
              "4  5adf3d64068401528a2aa60f  ...  https://www.nytimes.com/2018/04/24/world/canad...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"열의 개수 :\", len(df.columns))\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YoRw_jAZX9h",
        "outputId": "05f989ae-677c-4a70-9a4f-908596e883f4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "열의 개수 : 15\n",
            "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
            "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
            "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['headline'].isnull().values.any())    # NULL값 있는지 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdSoKRgwZhKO",
        "outputId": "b0ff407c-957a-4f9f-aa77-46dad85d3e6b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline = []\n",
        "# 헤드라인의 값들을 리스트로 저장\n",
        "headline.extend(list(df.headline.values))\n",
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y4Nx1FfZn5s",
        "outputId": "ba164f9b-7e29-4627-f7dd-1dbd3ea6a0c7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'Unknown',\n",
              " 'Unknown']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"총 샘플의 개수 : {}\".format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXdg7lKSZz3U",
        "outputId": "d93d62cf-a907-4697-be88-4dbd61ab024d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 1324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unkown값을 가진 샘플 제거\n",
        "headline = [word for word in headline if word != 'Unknown']\n",
        "print(\"노이즈값 제거 후 샘플의 개수 : {}\".format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3-OdOLTZ-VD",
        "outputId": "34d1fedc-7b8b-43c8-f679-e89f60bc52ec"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "노이즈값 제거 후 샘플의 개수 : 1214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sw2zTfwaKBo",
        "outputId": "6e815d4c-5caa-42fd-88ea-9d95408b3cec"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
              " 'Is School a Place for Self-Expression?']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 수행\n",
        "def repreprocessing(raw_sentence):\n",
        "  preproceseed_sentence = raw_sentence.encode('utf8').decode('ascii', 'ignore')\n",
        "  # 구두점 제거와 동시에 소문자화\n",
        "  return ''.join(word for word in preproceseed_sentence if word not in punctuation).lower()\n",
        "\n",
        "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
        "preprocessed_headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_SsBIqeaTYP",
        "outputId": "78519d98-c20a-484e-c049-a0ac4a284b88"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
              " 'epa to unveil a new rule its effect less science in policymaking',\n",
              " 'the new noma explained',\n",
              " 'how a bag of texas dirt  became a times tradition',\n",
              " 'is school a place for selfexpression']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_headline)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"단어 집합의 크기 : %d\" %vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30nUhwbga1QJ",
        "outputId": "bf4a01fb-2577-45a7-ba6b-724caf4fe2f1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 3494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "\n",
        "for sentence in preprocessed_headline:\n",
        "\n",
        "    # 각 샘플에 대한 정수 인코딩\n",
        "    encoded = tokenizer.texts_to_sequences([sentence])[0] \n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "freKKv38bHhQ",
        "outputId": "7c2d31ad-bdc9-480c-e147-577fb60e65eb"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99, 269],\n",
              " [99, 269, 371],\n",
              " [99, 269, 371, 1115],\n",
              " [99, 269, 371, 1115, 582],\n",
              " [99, 269, 371, 1115, 582, 52],\n",
              " [99, 269, 371, 1115, 582, 52, 7],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
              " [100, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인덱스로부터 단어를 찾는 index_to_word\n",
        "index_to_word = {}\n",
        "for key, value in tokenizer.word_index.items():    # 인덱스를 단어로 바꾸기 위해 index_to_word 생성\n",
        "  index_to_word[value] = key\n",
        "\n",
        "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfNo4FSPbcFO",
        "outputId": "d2ecf1a6-08ec-47d8-d73a-b11ed1a8f1ce"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 582번 단어 : offer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 긴 샘플의 길이 확인\n",
        "max_len = max(len(l) for l in sequences)\n",
        "print(\"샘플의 최대 길이 : {}\".format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2d0XcWLcJbo",
        "outputId": "acea1b95-e5b3-431d-d125-9691c62f37e5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 긴 샘플의 길이로 패딩\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYnL3rZkcfxm",
        "outputId": "ef493cd0-0c68-4bed-ffe6-ce5e6ecab48e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371 1115]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 맨 우측 단어만 레이블로 분리\n",
        "sequences = np.array(sequences)\n",
        "x = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "\n",
        "# 맨 우측의 정수값이 사라져 샘플의 길이가 24에서 23이 됨\n",
        "print(x[:3])\n",
        "print(y[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1mh9uyecp-8",
        "outputId": "59b2bbb1-c99b-4fd5-fa63-2e852a345cda"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  99 269]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  99 269 371]]\n",
            "[ 269  371 1115]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 데이터 y에 대하여 원-핫 인코딩\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "1BcndR3Hc0db"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 모델 설계하기"
      ],
      "metadata": {
        "id": "hMxrgTH_dQcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ],
      "metadata": {
        "id": "ceJwprJ4dKr2"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xrh8kpEdZul",
        "outputId": "be739674-5ce2-43f9-a1c3-bca78e2a15a2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "244/244 - 10s - loss: 7.6339 - accuracy: 0.0283 - 10s/epoch - 41ms/step\n",
            "Epoch 2/200\n",
            "244/244 - 8s - loss: 7.1070 - accuracy: 0.0327 - 8s/epoch - 31ms/step\n",
            "Epoch 3/200\n",
            "244/244 - 8s - loss: 6.9705 - accuracy: 0.0322 - 8s/epoch - 31ms/step\n",
            "Epoch 4/200\n",
            "244/244 - 8s - loss: 6.9864 - accuracy: 0.0379 - 8s/epoch - 31ms/step\n",
            "Epoch 5/200\n",
            "244/244 - 8s - loss: 6.7248 - accuracy: 0.0437 - 8s/epoch - 32ms/step\n",
            "Epoch 6/200\n",
            "244/244 - 8s - loss: 6.5663 - accuracy: 0.0451 - 8s/epoch - 31ms/step\n",
            "Epoch 7/200\n",
            "244/244 - 7s - loss: 6.3933 - accuracy: 0.0514 - 7s/epoch - 31ms/step\n",
            "Epoch 8/200\n",
            "244/244 - 7s - loss: 6.2026 - accuracy: 0.0569 - 7s/epoch - 31ms/step\n",
            "Epoch 9/200\n",
            "244/244 - 7s - loss: 6.0112 - accuracy: 0.0625 - 7s/epoch - 31ms/step\n",
            "Epoch 10/200\n",
            "244/244 - 8s - loss: 5.8309 - accuracy: 0.0655 - 8s/epoch - 31ms/step\n",
            "Epoch 11/200\n",
            "244/244 - 8s - loss: 5.6584 - accuracy: 0.0684 - 8s/epoch - 31ms/step\n",
            "Epoch 12/200\n",
            "244/244 - 8s - loss: 5.4968 - accuracy: 0.0716 - 8s/epoch - 31ms/step\n",
            "Epoch 13/200\n",
            "244/244 - 8s - loss: 5.3455 - accuracy: 0.0752 - 8s/epoch - 31ms/step\n",
            "Epoch 14/200\n",
            "244/244 - 8s - loss: 5.1993 - accuracy: 0.0824 - 8s/epoch - 31ms/step\n",
            "Epoch 15/200\n",
            "244/244 - 8s - loss: 5.0743 - accuracy: 0.0865 - 8s/epoch - 31ms/step\n",
            "Epoch 16/200\n",
            "244/244 - 8s - loss: 4.9277 - accuracy: 0.0933 - 8s/epoch - 31ms/step\n",
            "Epoch 17/200\n",
            "244/244 - 8s - loss: 4.7990 - accuracy: 0.1043 - 8s/epoch - 31ms/step\n",
            "Epoch 18/200\n",
            "244/244 - 8s - loss: 4.6812 - accuracy: 0.1143 - 8s/epoch - 31ms/step\n",
            "Epoch 19/200\n",
            "244/244 - 8s - loss: 4.5554 - accuracy: 0.1270 - 8s/epoch - 31ms/step\n",
            "Epoch 20/200\n",
            "244/244 - 7s - loss: 4.4393 - accuracy: 0.1419 - 7s/epoch - 31ms/step\n",
            "Epoch 21/200\n",
            "244/244 - 8s - loss: 4.3276 - accuracy: 0.1548 - 8s/epoch - 31ms/step\n",
            "Epoch 22/200\n",
            "244/244 - 8s - loss: 4.2149 - accuracy: 0.1720 - 8s/epoch - 32ms/step\n",
            "Epoch 23/200\n",
            "244/244 - 8s - loss: 4.1066 - accuracy: 0.1917 - 8s/epoch - 31ms/step\n",
            "Epoch 24/200\n",
            "244/244 - 8s - loss: 4.0017 - accuracy: 0.2080 - 8s/epoch - 31ms/step\n",
            "Epoch 25/200\n",
            "244/244 - 7s - loss: 3.9008 - accuracy: 0.2216 - 7s/epoch - 31ms/step\n",
            "Epoch 26/200\n",
            "244/244 - 8s - loss: 3.8030 - accuracy: 0.2376 - 8s/epoch - 31ms/step\n",
            "Epoch 27/200\n",
            "244/244 - 8s - loss: 3.7061 - accuracy: 0.2543 - 8s/epoch - 31ms/step\n",
            "Epoch 28/200\n",
            "244/244 - 8s - loss: 3.6160 - accuracy: 0.2671 - 8s/epoch - 31ms/step\n",
            "Epoch 29/200\n",
            "244/244 - 8s - loss: 3.5216 - accuracy: 0.2869 - 8s/epoch - 31ms/step\n",
            "Epoch 30/200\n",
            "244/244 - 8s - loss: 3.4355 - accuracy: 0.3013 - 8s/epoch - 31ms/step\n",
            "Epoch 31/200\n",
            "244/244 - 8s - loss: 3.3532 - accuracy: 0.3135 - 8s/epoch - 31ms/step\n",
            "Epoch 32/200\n",
            "244/244 - 8s - loss: 3.2713 - accuracy: 0.3274 - 8s/epoch - 31ms/step\n",
            "Epoch 33/200\n",
            "244/244 - 8s - loss: 3.1945 - accuracy: 0.3454 - 8s/epoch - 31ms/step\n",
            "Epoch 34/200\n",
            "244/244 - 8s - loss: 3.1143 - accuracy: 0.3579 - 8s/epoch - 31ms/step\n",
            "Epoch 35/200\n",
            "244/244 - 8s - loss: 3.0445 - accuracy: 0.3728 - 8s/epoch - 31ms/step\n",
            "Epoch 36/200\n",
            "244/244 - 8s - loss: 2.9772 - accuracy: 0.3857 - 8s/epoch - 31ms/step\n",
            "Epoch 37/200\n",
            "244/244 - 8s - loss: 2.9024 - accuracy: 0.4011 - 8s/epoch - 31ms/step\n",
            "Epoch 38/200\n",
            "244/244 - 8s - loss: 2.8375 - accuracy: 0.4101 - 8s/epoch - 32ms/step\n",
            "Epoch 39/200\n",
            "244/244 - 8s - loss: 2.7768 - accuracy: 0.4236 - 8s/epoch - 32ms/step\n",
            "Epoch 40/200\n",
            "244/244 - 8s - loss: 2.7125 - accuracy: 0.4373 - 8s/epoch - 31ms/step\n",
            "Epoch 41/200\n",
            "244/244 - 8s - loss: 2.6486 - accuracy: 0.4515 - 8s/epoch - 31ms/step\n",
            "Epoch 42/200\n",
            "244/244 - 7s - loss: 2.5921 - accuracy: 0.4639 - 7s/epoch - 31ms/step\n",
            "Epoch 43/200\n",
            "244/244 - 8s - loss: 2.5324 - accuracy: 0.4746 - 8s/epoch - 31ms/step\n",
            "Epoch 44/200\n",
            "244/244 - 8s - loss: 2.4780 - accuracy: 0.4906 - 8s/epoch - 31ms/step\n",
            "Epoch 45/200\n",
            "244/244 - 8s - loss: 2.4300 - accuracy: 0.4966 - 8s/epoch - 32ms/step\n",
            "Epoch 46/200\n",
            "244/244 - 8s - loss: 2.3712 - accuracy: 0.5092 - 8s/epoch - 31ms/step\n",
            "Epoch 47/200\n",
            "244/244 - 7s - loss: 2.3165 - accuracy: 0.5171 - 7s/epoch - 31ms/step\n",
            "Epoch 48/200\n",
            "244/244 - 8s - loss: 2.2647 - accuracy: 0.5307 - 8s/epoch - 31ms/step\n",
            "Epoch 49/200\n",
            "244/244 - 8s - loss: 2.2183 - accuracy: 0.5426 - 8s/epoch - 32ms/step\n",
            "Epoch 50/200\n",
            "244/244 - 8s - loss: 2.1669 - accuracy: 0.5472 - 8s/epoch - 31ms/step\n",
            "Epoch 51/200\n",
            "244/244 - 8s - loss: 2.1190 - accuracy: 0.5604 - 8s/epoch - 31ms/step\n",
            "Epoch 52/200\n",
            "244/244 - 7s - loss: 2.0721 - accuracy: 0.5714 - 7s/epoch - 31ms/step\n",
            "Epoch 53/200\n",
            "244/244 - 8s - loss: 2.0297 - accuracy: 0.5786 - 8s/epoch - 31ms/step\n",
            "Epoch 54/200\n",
            "244/244 - 8s - loss: 1.9842 - accuracy: 0.5902 - 8s/epoch - 31ms/step\n",
            "Epoch 55/200\n",
            "244/244 - 8s - loss: 1.9397 - accuracy: 0.5991 - 8s/epoch - 31ms/step\n",
            "Epoch 56/200\n",
            "244/244 - 8s - loss: 1.8960 - accuracy: 0.6098 - 8s/epoch - 31ms/step\n",
            "Epoch 57/200\n",
            "244/244 - 7s - loss: 1.8544 - accuracy: 0.6180 - 7s/epoch - 31ms/step\n",
            "Epoch 58/200\n",
            "244/244 - 8s - loss: 1.8103 - accuracy: 0.6332 - 8s/epoch - 31ms/step\n",
            "Epoch 59/200\n",
            "244/244 - 7s - loss: 1.7705 - accuracy: 0.6373 - 7s/epoch - 31ms/step\n",
            "Epoch 60/200\n",
            "244/244 - 8s - loss: 1.7304 - accuracy: 0.6437 - 8s/epoch - 31ms/step\n",
            "Epoch 61/200\n",
            "244/244 - 8s - loss: 1.6920 - accuracy: 0.6560 - 8s/epoch - 31ms/step\n",
            "Epoch 62/200\n",
            "244/244 - 8s - loss: 1.6533 - accuracy: 0.6626 - 8s/epoch - 32ms/step\n",
            "Epoch 63/200\n",
            "244/244 - 8s - loss: 1.6174 - accuracy: 0.6729 - 8s/epoch - 31ms/step\n",
            "Epoch 64/200\n",
            "244/244 - 8s - loss: 1.5851 - accuracy: 0.6794 - 8s/epoch - 31ms/step\n",
            "Epoch 65/200\n",
            "244/244 - 8s - loss: 1.5504 - accuracy: 0.6878 - 8s/epoch - 31ms/step\n",
            "Epoch 66/200\n",
            "244/244 - 8s - loss: 1.5140 - accuracy: 0.6954 - 8s/epoch - 31ms/step\n",
            "Epoch 67/200\n",
            "244/244 - 8s - loss: 1.4809 - accuracy: 0.7041 - 8s/epoch - 31ms/step\n",
            "Epoch 68/200\n",
            "244/244 - 7s - loss: 1.4435 - accuracy: 0.7114 - 7s/epoch - 31ms/step\n",
            "Epoch 69/200\n",
            "244/244 - 8s - loss: 1.7210 - accuracy: 0.6441 - 8s/epoch - 31ms/step\n",
            "Epoch 70/200\n",
            "244/244 - 8s - loss: 1.4229 - accuracy: 0.7146 - 8s/epoch - 31ms/step\n",
            "Epoch 71/200\n",
            "244/244 - 8s - loss: 1.3580 - accuracy: 0.7302 - 8s/epoch - 31ms/step\n",
            "Epoch 72/200\n",
            "244/244 - 8s - loss: 1.3217 - accuracy: 0.7379 - 8s/epoch - 31ms/step\n",
            "Epoch 73/200\n",
            "244/244 - 8s - loss: 1.2923 - accuracy: 0.7418 - 8s/epoch - 31ms/step\n",
            "Epoch 74/200\n",
            "244/244 - 8s - loss: 1.2665 - accuracy: 0.7486 - 8s/epoch - 31ms/step\n",
            "Epoch 75/200\n",
            "244/244 - 8s - loss: 1.2392 - accuracy: 0.7595 - 8s/epoch - 31ms/step\n",
            "Epoch 76/200\n",
            "244/244 - 8s - loss: 1.2127 - accuracy: 0.7621 - 8s/epoch - 31ms/step\n",
            "Epoch 77/200\n",
            "244/244 - 8s - loss: 1.1887 - accuracy: 0.7646 - 8s/epoch - 31ms/step\n",
            "Epoch 78/200\n",
            "244/244 - 8s - loss: 1.1647 - accuracy: 0.7701 - 8s/epoch - 31ms/step\n",
            "Epoch 79/200\n",
            "244/244 - 8s - loss: 1.1404 - accuracy: 0.7755 - 8s/epoch - 31ms/step\n",
            "Epoch 80/200\n",
            "244/244 - 7s - loss: 1.1137 - accuracy: 0.7847 - 7s/epoch - 31ms/step\n",
            "Epoch 81/200\n",
            "244/244 - 7s - loss: 1.0898 - accuracy: 0.7859 - 7s/epoch - 31ms/step\n",
            "Epoch 82/200\n",
            "244/244 - 8s - loss: 1.0656 - accuracy: 0.7932 - 8s/epoch - 31ms/step\n",
            "Epoch 83/200\n",
            "244/244 - 8s - loss: 1.0442 - accuracy: 0.7975 - 8s/epoch - 31ms/step\n",
            "Epoch 84/200\n",
            "244/244 - 8s - loss: 1.0184 - accuracy: 0.8019 - 8s/epoch - 31ms/step\n",
            "Epoch 85/200\n",
            "244/244 - 7s - loss: 0.9945 - accuracy: 0.8079 - 7s/epoch - 31ms/step\n",
            "Epoch 86/200\n",
            "244/244 - 8s - loss: 0.9751 - accuracy: 0.8087 - 8s/epoch - 31ms/step\n",
            "Epoch 87/200\n",
            "244/244 - 8s - loss: 0.9557 - accuracy: 0.8133 - 8s/epoch - 31ms/step\n",
            "Epoch 88/200\n",
            "244/244 - 8s - loss: 0.9344 - accuracy: 0.8165 - 8s/epoch - 31ms/step\n",
            "Epoch 89/200\n",
            "244/244 - 8s - loss: 0.9134 - accuracy: 0.8243 - 8s/epoch - 31ms/step\n",
            "Epoch 90/200\n",
            "244/244 - 8s - loss: 0.8894 - accuracy: 0.8255 - 8s/epoch - 31ms/step\n",
            "Epoch 91/200\n",
            "244/244 - 7s - loss: 0.8690 - accuracy: 0.8280 - 7s/epoch - 30ms/step\n",
            "Epoch 92/200\n",
            "244/244 - 7s - loss: 0.8508 - accuracy: 0.8313 - 7s/epoch - 31ms/step\n",
            "Epoch 93/200\n",
            "244/244 - 7s - loss: 0.8360 - accuracy: 0.8346 - 7s/epoch - 31ms/step\n",
            "Epoch 94/200\n",
            "244/244 - 7s - loss: 0.8199 - accuracy: 0.8378 - 7s/epoch - 30ms/step\n",
            "Epoch 95/200\n",
            "244/244 - 8s - loss: 0.8012 - accuracy: 0.8417 - 8s/epoch - 31ms/step\n",
            "Epoch 96/200\n",
            "244/244 - 8s - loss: 0.7861 - accuracy: 0.8442 - 8s/epoch - 31ms/step\n",
            "Epoch 97/200\n",
            "244/244 - 7s - loss: 0.7671 - accuracy: 0.8508 - 7s/epoch - 31ms/step\n",
            "Epoch 98/200\n",
            "244/244 - 7s - loss: 0.7470 - accuracy: 0.8510 - 7s/epoch - 31ms/step\n",
            "Epoch 99/200\n",
            "244/244 - 8s - loss: 0.7277 - accuracy: 0.8530 - 8s/epoch - 31ms/step\n",
            "Epoch 100/200\n",
            "244/244 - 8s - loss: 0.7123 - accuracy: 0.8580 - 8s/epoch - 31ms/step\n",
            "Epoch 101/200\n",
            "244/244 - 7s - loss: 0.6976 - accuracy: 0.8592 - 7s/epoch - 31ms/step\n",
            "Epoch 102/200\n",
            "244/244 - 8s - loss: 0.6859 - accuracy: 0.8636 - 8s/epoch - 31ms/step\n",
            "Epoch 103/200\n",
            "244/244 - 8s - loss: 0.6669 - accuracy: 0.8666 - 8s/epoch - 31ms/step\n",
            "Epoch 104/200\n",
            "244/244 - 8s - loss: 0.6515 - accuracy: 0.8677 - 8s/epoch - 31ms/step\n",
            "Epoch 105/200\n",
            "244/244 - 7s - loss: 0.6359 - accuracy: 0.8725 - 7s/epoch - 31ms/step\n",
            "Epoch 106/200\n",
            "244/244 - 8s - loss: 0.6249 - accuracy: 0.8762 - 8s/epoch - 31ms/step\n",
            "Epoch 107/200\n",
            "244/244 - 8s - loss: 0.6122 - accuracy: 0.8768 - 8s/epoch - 31ms/step\n",
            "Epoch 108/200\n",
            "244/244 - 7s - loss: 0.6004 - accuracy: 0.8771 - 7s/epoch - 31ms/step\n",
            "Epoch 109/200\n",
            "244/244 - 7s - loss: 0.5880 - accuracy: 0.8809 - 7s/epoch - 31ms/step\n",
            "Epoch 110/200\n",
            "244/244 - 8s - loss: 0.5909 - accuracy: 0.8826 - 8s/epoch - 31ms/step\n",
            "Epoch 111/200\n",
            "244/244 - 8s - loss: 0.5960 - accuracy: 0.8820 - 8s/epoch - 31ms/step\n",
            "Epoch 112/200\n",
            "244/244 - 8s - loss: 0.5859 - accuracy: 0.8827 - 8s/epoch - 31ms/step\n",
            "Epoch 113/200\n",
            "244/244 - 8s - loss: 0.5496 - accuracy: 0.8866 - 8s/epoch - 31ms/step\n",
            "Epoch 114/200\n",
            "244/244 - 7s - loss: 0.5302 - accuracy: 0.8918 - 7s/epoch - 31ms/step\n",
            "Epoch 115/200\n",
            "244/244 - 8s - loss: 0.5180 - accuracy: 0.8932 - 8s/epoch - 31ms/step\n",
            "Epoch 116/200\n",
            "244/244 - 8s - loss: 0.5074 - accuracy: 0.8963 - 8s/epoch - 31ms/step\n",
            "Epoch 117/200\n",
            "244/244 - 8s - loss: 0.4991 - accuracy: 0.8961 - 8s/epoch - 31ms/step\n",
            "Epoch 118/200\n",
            "244/244 - 8s - loss: 0.4910 - accuracy: 0.8972 - 8s/epoch - 31ms/step\n",
            "Epoch 119/200\n",
            "244/244 - 8s - loss: 0.4798 - accuracy: 0.9013 - 8s/epoch - 31ms/step\n",
            "Epoch 120/200\n",
            "244/244 - 8s - loss: 0.4739 - accuracy: 0.9007 - 8s/epoch - 32ms/step\n",
            "Epoch 121/200\n",
            "244/244 - 8s - loss: 0.4655 - accuracy: 0.9017 - 8s/epoch - 31ms/step\n",
            "Epoch 122/200\n",
            "244/244 - 8s - loss: 0.4578 - accuracy: 0.9031 - 8s/epoch - 31ms/step\n",
            "Epoch 123/200\n",
            "244/244 - 8s - loss: 0.4508 - accuracy: 0.9027 - 8s/epoch - 32ms/step\n",
            "Epoch 124/200\n",
            "244/244 - 8s - loss: 0.4434 - accuracy: 0.9049 - 8s/epoch - 32ms/step\n",
            "Epoch 125/200\n",
            "244/244 - 8s - loss: 0.4342 - accuracy: 0.9073 - 8s/epoch - 31ms/step\n",
            "Epoch 126/200\n",
            "244/244 - 8s - loss: 0.4296 - accuracy: 0.9062 - 8s/epoch - 31ms/step\n",
            "Epoch 127/200\n",
            "244/244 - 8s - loss: 0.4551 - accuracy: 0.9034 - 8s/epoch - 31ms/step\n",
            "Epoch 128/200\n",
            "244/244 - 8s - loss: 0.4551 - accuracy: 0.9017 - 8s/epoch - 31ms/step\n",
            "Epoch 129/200\n",
            "244/244 - 8s - loss: 0.4284 - accuracy: 0.9063 - 8s/epoch - 31ms/step\n",
            "Epoch 130/200\n",
            "244/244 - 8s - loss: 0.4122 - accuracy: 0.9102 - 8s/epoch - 31ms/step\n",
            "Epoch 131/200\n",
            "244/244 - 7s - loss: 0.4004 - accuracy: 0.9107 - 7s/epoch - 31ms/step\n",
            "Epoch 132/200\n",
            "244/244 - 8s - loss: 0.3908 - accuracy: 0.9136 - 8s/epoch - 31ms/step\n",
            "Epoch 133/200\n",
            "244/244 - 8s - loss: 0.3873 - accuracy: 0.9107 - 8s/epoch - 31ms/step\n",
            "Epoch 134/200\n",
            "244/244 - 8s - loss: 0.3809 - accuracy: 0.9131 - 8s/epoch - 31ms/step\n",
            "Epoch 135/200\n",
            "244/244 - 7s - loss: 0.3762 - accuracy: 0.9136 - 7s/epoch - 31ms/step\n",
            "Epoch 136/200\n",
            "244/244 - 8s - loss: 0.3710 - accuracy: 0.9127 - 8s/epoch - 31ms/step\n",
            "Epoch 137/200\n",
            "244/244 - 8s - loss: 0.3650 - accuracy: 0.9138 - 8s/epoch - 31ms/step\n",
            "Epoch 138/200\n",
            "244/244 - 8s - loss: 0.3597 - accuracy: 0.9155 - 8s/epoch - 31ms/step\n",
            "Epoch 139/200\n",
            "244/244 - 7s - loss: 0.3571 - accuracy: 0.9134 - 7s/epoch - 31ms/step\n",
            "Epoch 140/200\n",
            "244/244 - 8s - loss: 0.3523 - accuracy: 0.9141 - 8s/epoch - 31ms/step\n",
            "Epoch 141/200\n",
            "244/244 - 8s - loss: 0.3476 - accuracy: 0.9161 - 8s/epoch - 31ms/step\n",
            "Epoch 142/200\n",
            "244/244 - 8s - loss: 0.3437 - accuracy: 0.9158 - 8s/epoch - 31ms/step\n",
            "Epoch 143/200\n",
            "244/244 - 8s - loss: 0.3410 - accuracy: 0.9141 - 8s/epoch - 31ms/step\n",
            "Epoch 144/200\n",
            "244/244 - 8s - loss: 0.3385 - accuracy: 0.9159 - 8s/epoch - 31ms/step\n",
            "Epoch 145/200\n",
            "244/244 - 8s - loss: 0.3496 - accuracy: 0.9123 - 8s/epoch - 31ms/step\n",
            "Epoch 146/200\n",
            "244/244 - 8s - loss: 0.4001 - accuracy: 0.9038 - 8s/epoch - 31ms/step\n",
            "Epoch 147/200\n",
            "244/244 - 7s - loss: 0.3530 - accuracy: 0.9122 - 7s/epoch - 31ms/step\n",
            "Epoch 148/200\n",
            "244/244 - 8s - loss: 0.3324 - accuracy: 0.9172 - 8s/epoch - 31ms/step\n",
            "Epoch 149/200\n",
            "244/244 - 8s - loss: 0.3227 - accuracy: 0.9152 - 8s/epoch - 31ms/step\n",
            "Epoch 150/200\n",
            "244/244 - 8s - loss: 0.3186 - accuracy: 0.9163 - 8s/epoch - 31ms/step\n",
            "Epoch 151/200\n",
            "244/244 - 7s - loss: 0.3151 - accuracy: 0.9172 - 7s/epoch - 31ms/step\n",
            "Epoch 152/200\n",
            "244/244 - 8s - loss: 0.3131 - accuracy: 0.9176 - 8s/epoch - 31ms/step\n",
            "Epoch 153/200\n",
            "244/244 - 8s - loss: 0.3109 - accuracy: 0.9185 - 8s/epoch - 31ms/step\n",
            "Epoch 154/200\n",
            "244/244 - 8s - loss: 0.3090 - accuracy: 0.9163 - 8s/epoch - 31ms/step\n",
            "Epoch 155/200\n",
            "244/244 - 8s - loss: 0.3066 - accuracy: 0.9167 - 8s/epoch - 31ms/step\n",
            "Epoch 156/200\n",
            "244/244 - 7s - loss: 0.3049 - accuracy: 0.9155 - 7s/epoch - 31ms/step\n",
            "Epoch 157/200\n",
            "244/244 - 8s - loss: 0.3044 - accuracy: 0.9168 - 8s/epoch - 32ms/step\n",
            "Epoch 158/200\n",
            "244/244 - 8s - loss: 0.3025 - accuracy: 0.9162 - 8s/epoch - 32ms/step\n",
            "Epoch 159/200\n",
            "244/244 - 8s - loss: 0.3006 - accuracy: 0.9161 - 8s/epoch - 31ms/step\n",
            "Epoch 160/200\n",
            "244/244 - 8s - loss: 0.3023 - accuracy: 0.9161 - 8s/epoch - 31ms/step\n",
            "Epoch 161/200\n",
            "244/244 - 8s - loss: 0.3003 - accuracy: 0.9164 - 8s/epoch - 31ms/step\n",
            "Epoch 162/200\n",
            "244/244 - 8s - loss: 0.2961 - accuracy: 0.9162 - 8s/epoch - 31ms/step\n",
            "Epoch 163/200\n",
            "244/244 - 8s - loss: 0.2983 - accuracy: 0.9155 - 8s/epoch - 31ms/step\n",
            "Epoch 164/200\n",
            "244/244 - 7s - loss: 0.3089 - accuracy: 0.9141 - 7s/epoch - 31ms/step\n",
            "Epoch 165/200\n",
            "244/244 - 7s - loss: 0.3194 - accuracy: 0.9123 - 7s/epoch - 31ms/step\n",
            "Epoch 166/200\n",
            "244/244 - 8s - loss: 0.3073 - accuracy: 0.9148 - 8s/epoch - 31ms/step\n",
            "Epoch 167/200\n",
            "244/244 - 8s - loss: 0.2948 - accuracy: 0.9158 - 8s/epoch - 31ms/step\n",
            "Epoch 168/200\n",
            "244/244 - 8s - loss: 0.2913 - accuracy: 0.9148 - 8s/epoch - 31ms/step\n",
            "Epoch 169/200\n",
            "244/244 - 7s - loss: 0.2856 - accuracy: 0.9171 - 7s/epoch - 31ms/step\n",
            "Epoch 170/200\n",
            "244/244 - 8s - loss: 0.2843 - accuracy: 0.9163 - 8s/epoch - 31ms/step\n",
            "Epoch 171/200\n",
            "244/244 - 8s - loss: 0.2838 - accuracy: 0.9161 - 8s/epoch - 31ms/step\n",
            "Epoch 172/200\n",
            "244/244 - 8s - loss: 0.2815 - accuracy: 0.9173 - 8s/epoch - 31ms/step\n",
            "Epoch 173/200\n",
            "244/244 - 8s - loss: 0.2815 - accuracy: 0.9172 - 8s/epoch - 31ms/step\n",
            "Epoch 174/200\n",
            "244/244 - 8s - loss: 0.2825 - accuracy: 0.9152 - 8s/epoch - 31ms/step\n",
            "Epoch 175/200\n",
            "244/244 - 8s - loss: 0.2805 - accuracy: 0.9167 - 8s/epoch - 31ms/step\n",
            "Epoch 176/200\n",
            "244/244 - 8s - loss: 0.2795 - accuracy: 0.9153 - 8s/epoch - 31ms/step\n",
            "Epoch 177/200\n",
            "244/244 - 8s - loss: 0.2773 - accuracy: 0.9168 - 8s/epoch - 31ms/step\n",
            "Epoch 178/200\n",
            "244/244 - 8s - loss: 0.2780 - accuracy: 0.9163 - 8s/epoch - 31ms/step\n",
            "Epoch 179/200\n",
            "244/244 - 8s - loss: 0.2780 - accuracy: 0.9166 - 8s/epoch - 31ms/step\n",
            "Epoch 180/200\n",
            "244/244 - 8s - loss: 0.2769 - accuracy: 0.9157 - 8s/epoch - 31ms/step\n",
            "Epoch 181/200\n",
            "244/244 - 8s - loss: 0.2768 - accuracy: 0.9162 - 8s/epoch - 31ms/step\n",
            "Epoch 182/200\n",
            "244/244 - 8s - loss: 0.2961 - accuracy: 0.9112 - 8s/epoch - 31ms/step\n",
            "Epoch 183/200\n",
            "244/244 - 8s - loss: 0.3270 - accuracy: 0.9072 - 8s/epoch - 31ms/step\n",
            "Epoch 184/200\n",
            "244/244 - 8s - loss: 0.2871 - accuracy: 0.9146 - 8s/epoch - 31ms/step\n",
            "Epoch 185/200\n",
            "244/244 - 8s - loss: 0.2759 - accuracy: 0.9148 - 8s/epoch - 31ms/step\n",
            "Epoch 186/200\n",
            "244/244 - 8s - loss: 0.2719 - accuracy: 0.9164 - 8s/epoch - 31ms/step\n",
            "Epoch 187/200\n",
            "244/244 - 8s - loss: 0.2711 - accuracy: 0.9164 - 8s/epoch - 31ms/step\n",
            "Epoch 188/200\n",
            "244/244 - 8s - loss: 0.2700 - accuracy: 0.9154 - 8s/epoch - 31ms/step\n",
            "Epoch 189/200\n",
            "244/244 - 8s - loss: 0.2700 - accuracy: 0.9184 - 8s/epoch - 31ms/step\n",
            "Epoch 190/200\n",
            "244/244 - 8s - loss: 0.2698 - accuracy: 0.9154 - 8s/epoch - 31ms/step\n",
            "Epoch 191/200\n",
            "244/244 - 8s - loss: 0.2702 - accuracy: 0.9157 - 8s/epoch - 31ms/step\n",
            "Epoch 192/200\n",
            "244/244 - 8s - loss: 0.2700 - accuracy: 0.9159 - 8s/epoch - 31ms/step\n",
            "Epoch 193/200\n",
            "244/244 - 8s - loss: 0.2685 - accuracy: 0.9166 - 8s/epoch - 31ms/step\n",
            "Epoch 194/200\n",
            "244/244 - 8s - loss: 0.2678 - accuracy: 0.9168 - 8s/epoch - 31ms/step\n",
            "Epoch 195/200\n",
            "244/244 - 8s - loss: 0.2688 - accuracy: 0.9152 - 8s/epoch - 31ms/step\n",
            "Epoch 196/200\n",
            "244/244 - 8s - loss: 0.2687 - accuracy: 0.9161 - 8s/epoch - 31ms/step\n",
            "Epoch 197/200\n",
            "244/244 - 8s - loss: 0.2680 - accuracy: 0.9167 - 8s/epoch - 31ms/step\n",
            "Epoch 198/200\n",
            "244/244 - 8s - loss: 0.2695 - accuracy: 0.9159 - 8s/epoch - 31ms/step\n",
            "Epoch 199/200\n",
            "244/244 - 8s - loss: 0.2695 - accuracy: 0.9162 - 8s/epoch - 31ms/step\n",
            "Epoch 200/200\n",
            "244/244 - 8s - loss: 0.2702 - accuracy: 0.9152 - 8s/epoch - 31ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcfeee34ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장을 생성하는 함수\n",
        "def sentence_generation(model, tokenizer, current_word, n):  # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "\n",
        "  # n번 반복\n",
        "  for _ in range(n):\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "    # 입력한 x(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis=1)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    # 현재 단어 + ' ' + 에측 단어를 현재 단어로 변경\n",
        "    current_word = current_word + ' ' + word\n",
        "\n",
        "    # 예측 단어를 문장에 저장\n",
        "    sentence = sentence + ' ' + word\n",
        "\n",
        "  sentence = init_word + sentence\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "kIZeHZjceVf_"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 단어 'i'에 대해서 10개의 단어를 추가 생성\n",
        "print(sentence_generation(model, tokenizer, 'i', 10))\n",
        "\n",
        "# 임의의 단어 'how'에 대해서 10개의 단어를 추가 생성\n",
        "print(sentence_generation(model, tokenizer, 'how', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-BtpzX-fNA1",
        "outputId": "cee36737-8aba-4686-f89f-a53c8b6cf995"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i cant jump ship from facebook yet own pruitt a trail\n",
            "how to make facebook more accountable are on far the tip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) 문자 단위 RNN\n",
        "## 1. 문자 단위 RNN 언어 모델\n",
        "### 1) 데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "B3dch2MMkOtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드, 특수문자 제거, 단어 소문자화\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
        "\n",
        "f = open('11-0.txt', 'rb')\n",
        "sentences = []\n",
        "for sentence in f:    # 데이터로부터 한 줄씩 읽는다\n",
        "  sentence = sentence.strip()    # strip()을 통해 \\r, \\n을 제거한다\n",
        "  sentence = sentence.lower()    # 소문자화\n",
        "  sentence = sentence.decode('ascii', 'ignore')    # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
        "  if len(sentence) > 0:\n",
        "    sentences.append(sentence)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "D7o0AxtnkLjb"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gznezCwZlmVH",
        "outputId": "da0d4533-2ef2-4569-c384-31d2f4af8597"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 문자열로 통합\n",
        "total_data = ' '.join(sentences)\n",
        "print(\"문자열의 길이 또는 총 문자의 개수 : %d\" % len(total_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caPNGzb_looi",
        "outputId": "ebacbab8-c17b-4b62-e1e9-68666e0f17d9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자열의 길이 또는 총 문자의 개수 : 159484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_data[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn-we2G9l0v6",
        "outputId": "cd1a0d88-4c0b-472a-f182-810cd2d7dab2"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 문자열로부터 문자 집합\n",
        "char_vocab = sorted(list(set(total_data)))\n",
        "vocab_size = len(char_vocab)\n",
        "print(\"문자 집합의 크기 : {}\".format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCGS8IMsl3ii",
        "outputId": "40359985-ec77-41a9-cf27-0f4d5ca3db91"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합의 크기 : 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자에 고유한 정수 부여\n",
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
        "print(\"문자 집합 :\", char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a7v54wzmFHj",
        "outputId": "6334dd8e-729b-4577-e311-229362c82bb9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 : {' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수로부터 문자를 리턴하는 index_to_char 작성\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key"
      ],
      "metadata": {
        "id": "9xCVA3BQmYZr"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appl(입력 시퀀스) -> pple(예측해야 하는 시퀀스)\n",
        "train_x = 'appl'\n",
        "train_y = 'pple'"
      ],
      "metadata": {
        "id": "IzjH5ZynmlHZ"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 60\n",
        "\n",
        "# 문자열의 길이를 seq_length로 나누면 전처리 후 생겨날 샘플 수\n",
        "n_samples = int(np.floor((len(total_data) - 1) / seq_length))\n",
        "print(\"샘플의 수 : {}\".format(n_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXkQ4Rfym6Fi",
        "outputId": "5a961730-3594-4ef3-95b0-666241065896"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 수 : 2658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "  # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 pick\n",
        "  x_sample = total_data[i * seq_length: (i+1) * seq_length]\n",
        "\n",
        "  # 정수 인코딩\n",
        "  x_encoded = [char_to_index[c] for c in x_sample]\n",
        "  train_x.append(x_encoded)\n",
        "\n",
        "  # 오른쪽으로 1칸 쉬프트\n",
        "  y_sample = total_data[i * seq_length + 1: (i+1) * seq_length + 1]\n",
        "  y_encoded = [char_to_index[c] for c in y_sample]\n",
        "  train_y.append(y_encoded)"
      ],
      "metadata": {
        "id": "yxb6aECAnHsS"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x 데이터의 첫번째 샘플 :', train_x[0])\n",
        "print('y 데이터의 첫번째 샘플 :', train_y[0])\n",
        "print('-'*50)\n",
        "print('x 데이터의 첫번째 샘플 디코딩 :', [index_to_char[i] for i in train_x[0]])\n",
        "print('y 데이터의 첫번째 샘플 디코딩 :', [index_to_char[i] for i in train_y[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jByP9fy1nvVr",
        "outputId": "a1da5f25-878c-40fc-a891-cd81b9b54df4"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x 데이터의 첫번째 샘플 : [49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n",
            "y 데이터의 첫번째 샘플 : [37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n",
            "--------------------------------------------------\n",
            "x 데이터의 첫번째 샘플 디코딩 : ['t', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a']\n",
            "y 데이터의 첫번째 샘플 디코딩 : ['h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a', 'n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_y[1]은 train_x[1]에서 오른쪽으로 한 칸 쉬프트 된 문장\n",
        "print(train_x[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97tzHZPToBt7",
        "outputId": "789fbeca-b131-457f-8f1e-df4f6a125f77"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_y[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WbopIdooUEC",
        "outputId": "ca545cc6-8f3c-4be4-c4a2-fddf2c83f2d0"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = to_categorical(train_x)\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "print('train_x의 크기(shape) : {}'.format(train_x.shape))    # 원-핫 인코딩\n",
        "print('train_y의 크기(shape) : {}'.format(train_y.shape))    # 원-핫 인코딩"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP2qhkZpoVXq",
        "outputId": "f6e23d9d-aab1-480a-f0ec-d1a40b702454"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x의 크기(shape) : (2658, 60, 56)\n",
            "train_y의 크기(shape) : (2658, 60, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 모델 설계하기"
      ],
      "metadata": {
        "id": "M0GXrRXyovTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
        "\n",
        "hidden_units = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(None, train_x.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(hidden_units, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_x, train_y, epochs=80, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a796HZtUorHr",
        "outputId": "ca330026-8c09-40e1-a628-ec2036cdbc6d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "84/84 - 45s - loss: 3.0681 - accuracy: 0.1834 - 45s/epoch - 541ms/step\n",
            "Epoch 2/80\n",
            "84/84 - 42s - loss: 2.8110 - accuracy: 0.2270 - 42s/epoch - 500ms/step\n",
            "Epoch 3/80\n",
            "84/84 - 42s - loss: 2.4642 - accuracy: 0.3113 - 42s/epoch - 501ms/step\n",
            "Epoch 4/80\n",
            "84/84 - 42s - loss: 2.3390 - accuracy: 0.3375 - 42s/epoch - 498ms/step\n",
            "Epoch 5/80\n",
            "84/84 - 42s - loss: 2.2386 - accuracy: 0.3622 - 42s/epoch - 497ms/step\n",
            "Epoch 6/80\n",
            "84/84 - 42s - loss: 2.1563 - accuracy: 0.3844 - 42s/epoch - 500ms/step\n",
            "Epoch 7/80\n",
            "84/84 - 43s - loss: 2.1035 - accuracy: 0.3972 - 43s/epoch - 507ms/step\n",
            "Epoch 8/80\n",
            "84/84 - 43s - loss: 2.0453 - accuracy: 0.4118 - 43s/epoch - 506ms/step\n",
            "Epoch 9/80\n",
            "84/84 - 43s - loss: 1.9949 - accuracy: 0.4233 - 43s/epoch - 509ms/step\n",
            "Epoch 10/80\n",
            "84/84 - 43s - loss: 1.9552 - accuracy: 0.4355 - 43s/epoch - 508ms/step\n",
            "Epoch 11/80\n",
            "84/84 - 43s - loss: 1.9194 - accuracy: 0.4434 - 43s/epoch - 507ms/step\n",
            "Epoch 12/80\n",
            "84/84 - 42s - loss: 1.8807 - accuracy: 0.4539 - 42s/epoch - 501ms/step\n",
            "Epoch 13/80\n",
            "84/84 - 42s - loss: 1.8455 - accuracy: 0.4631 - 42s/epoch - 506ms/step\n",
            "Epoch 14/80\n",
            "84/84 - 43s - loss: 1.8150 - accuracy: 0.4714 - 43s/epoch - 506ms/step\n",
            "Epoch 15/80\n",
            "84/84 - 42s - loss: 1.7828 - accuracy: 0.4809 - 42s/epoch - 499ms/step\n",
            "Epoch 16/80\n",
            "84/84 - 42s - loss: 1.7562 - accuracy: 0.4875 - 42s/epoch - 500ms/step\n",
            "Epoch 17/80\n",
            "84/84 - 42s - loss: 1.7264 - accuracy: 0.4953 - 42s/epoch - 505ms/step\n",
            "Epoch 18/80\n",
            "84/84 - 42s - loss: 1.6985 - accuracy: 0.5031 - 42s/epoch - 498ms/step\n",
            "Epoch 19/80\n",
            "84/84 - 42s - loss: 1.6734 - accuracy: 0.5089 - 42s/epoch - 502ms/step\n",
            "Epoch 20/80\n",
            "84/84 - 42s - loss: 1.6463 - accuracy: 0.5161 - 42s/epoch - 500ms/step\n",
            "Epoch 21/80\n",
            "84/84 - 42s - loss: 1.6210 - accuracy: 0.5233 - 42s/epoch - 500ms/step\n",
            "Epoch 22/80\n",
            "84/84 - 42s - loss: 1.5990 - accuracy: 0.5286 - 42s/epoch - 500ms/step\n",
            "Epoch 23/80\n",
            "84/84 - 42s - loss: 1.5736 - accuracy: 0.5346 - 42s/epoch - 500ms/step\n",
            "Epoch 24/80\n",
            "84/84 - 42s - loss: 1.5535 - accuracy: 0.5400 - 42s/epoch - 502ms/step\n",
            "Epoch 25/80\n",
            "84/84 - 42s - loss: 1.5278 - accuracy: 0.5478 - 42s/epoch - 499ms/step\n",
            "Epoch 26/80\n",
            "84/84 - 42s - loss: 1.5066 - accuracy: 0.5540 - 42s/epoch - 499ms/step\n",
            "Epoch 27/80\n",
            "84/84 - 42s - loss: 1.4824 - accuracy: 0.5605 - 42s/epoch - 500ms/step\n",
            "Epoch 28/80\n",
            "84/84 - 42s - loss: 1.4622 - accuracy: 0.5666 - 42s/epoch - 500ms/step\n",
            "Epoch 29/80\n",
            "84/84 - 42s - loss: 1.4419 - accuracy: 0.5713 - 42s/epoch - 502ms/step\n",
            "Epoch 30/80\n",
            "84/84 - 42s - loss: 1.4228 - accuracy: 0.5774 - 42s/epoch - 505ms/step\n",
            "Epoch 31/80\n",
            "84/84 - 43s - loss: 1.4023 - accuracy: 0.5832 - 43s/epoch - 506ms/step\n",
            "Epoch 32/80\n",
            "84/84 - 42s - loss: 1.3804 - accuracy: 0.5899 - 42s/epoch - 501ms/step\n",
            "Epoch 33/80\n",
            "84/84 - 42s - loss: 1.3583 - accuracy: 0.5951 - 42s/epoch - 498ms/step\n",
            "Epoch 34/80\n",
            "84/84 - 42s - loss: 1.3352 - accuracy: 0.6021 - 42s/epoch - 499ms/step\n",
            "Epoch 35/80\n",
            "84/84 - 42s - loss: 1.3187 - accuracy: 0.6066 - 42s/epoch - 498ms/step\n",
            "Epoch 36/80\n",
            "84/84 - 42s - loss: 1.2986 - accuracy: 0.6119 - 42s/epoch - 501ms/step\n",
            "Epoch 37/80\n",
            "84/84 - 42s - loss: 1.2811 - accuracy: 0.6169 - 42s/epoch - 501ms/step\n",
            "Epoch 38/80\n",
            "84/84 - 42s - loss: 1.2581 - accuracy: 0.6238 - 42s/epoch - 500ms/step\n",
            "Epoch 39/80\n",
            "84/84 - 42s - loss: 1.2363 - accuracy: 0.6291 - 42s/epoch - 503ms/step\n",
            "Epoch 40/80\n",
            "84/84 - 42s - loss: 1.2169 - accuracy: 0.6354 - 42s/epoch - 503ms/step\n",
            "Epoch 41/80\n",
            "84/84 - 42s - loss: 1.1999 - accuracy: 0.6397 - 42s/epoch - 499ms/step\n",
            "Epoch 42/80\n",
            "84/84 - 42s - loss: 1.1779 - accuracy: 0.6460 - 42s/epoch - 501ms/step\n",
            "Epoch 43/80\n",
            "84/84 - 42s - loss: 1.1555 - accuracy: 0.6528 - 42s/epoch - 499ms/step\n",
            "Epoch 44/80\n",
            "84/84 - 42s - loss: 1.1353 - accuracy: 0.6582 - 42s/epoch - 498ms/step\n",
            "Epoch 45/80\n",
            "84/84 - 42s - loss: 1.1175 - accuracy: 0.6640 - 42s/epoch - 504ms/step\n",
            "Epoch 46/80\n",
            "84/84 - 42s - loss: 1.0965 - accuracy: 0.6701 - 42s/epoch - 505ms/step\n",
            "Epoch 47/80\n",
            "84/84 - 44s - loss: 1.0745 - accuracy: 0.6757 - 44s/epoch - 518ms/step\n",
            "Epoch 48/80\n",
            "84/84 - 45s - loss: 1.0504 - accuracy: 0.6835 - 45s/epoch - 539ms/step\n",
            "Epoch 49/80\n",
            "84/84 - 42s - loss: 1.0335 - accuracy: 0.6891 - 42s/epoch - 501ms/step\n",
            "Epoch 50/80\n",
            "84/84 - 42s - loss: 1.0052 - accuracy: 0.6972 - 42s/epoch - 500ms/step\n",
            "Epoch 51/80\n",
            "84/84 - 42s - loss: 0.9841 - accuracy: 0.7037 - 42s/epoch - 506ms/step\n",
            "Epoch 52/80\n",
            "84/84 - 42s - loss: 0.9656 - accuracy: 0.7102 - 42s/epoch - 504ms/step\n",
            "Epoch 53/80\n",
            "84/84 - 42s - loss: 0.9422 - accuracy: 0.7177 - 42s/epoch - 505ms/step\n",
            "Epoch 54/80\n",
            "84/84 - 42s - loss: 0.9191 - accuracy: 0.7245 - 42s/epoch - 506ms/step\n",
            "Epoch 55/80\n",
            "84/84 - 42s - loss: 0.8953 - accuracy: 0.7320 - 42s/epoch - 499ms/step\n",
            "Epoch 56/80\n",
            "84/84 - 42s - loss: 0.8748 - accuracy: 0.7388 - 42s/epoch - 502ms/step\n",
            "Epoch 57/80\n",
            "84/84 - 42s - loss: 0.8509 - accuracy: 0.7469 - 42s/epoch - 502ms/step\n",
            "Epoch 58/80\n",
            "84/84 - 42s - loss: 0.8312 - accuracy: 0.7533 - 42s/epoch - 503ms/step\n",
            "Epoch 59/80\n",
            "84/84 - 42s - loss: 0.8081 - accuracy: 0.7589 - 42s/epoch - 500ms/step\n",
            "Epoch 60/80\n",
            "84/84 - 42s - loss: 0.7879 - accuracy: 0.7665 - 42s/epoch - 500ms/step\n",
            "Epoch 61/80\n",
            "84/84 - 42s - loss: 0.7635 - accuracy: 0.7748 - 42s/epoch - 499ms/step\n",
            "Epoch 62/80\n",
            "84/84 - 42s - loss: 0.7453 - accuracy: 0.7790 - 42s/epoch - 506ms/step\n",
            "Epoch 63/80\n",
            "84/84 - 42s - loss: 0.7215 - accuracy: 0.7881 - 42s/epoch - 504ms/step\n",
            "Epoch 64/80\n",
            "84/84 - 43s - loss: 0.7016 - accuracy: 0.7948 - 43s/epoch - 506ms/step\n",
            "Epoch 65/80\n",
            "84/84 - 42s - loss: 0.6801 - accuracy: 0.8010 - 42s/epoch - 504ms/step\n",
            "Epoch 66/80\n",
            "84/84 - 42s - loss: 0.6599 - accuracy: 0.8080 - 42s/epoch - 500ms/step\n",
            "Epoch 67/80\n",
            "84/84 - 42s - loss: 0.6386 - accuracy: 0.8147 - 42s/epoch - 503ms/step\n",
            "Epoch 68/80\n",
            "84/84 - 42s - loss: 0.6247 - accuracy: 0.8195 - 42s/epoch - 502ms/step\n",
            "Epoch 69/80\n",
            "84/84 - 42s - loss: 0.5984 - accuracy: 0.8286 - 42s/epoch - 500ms/step\n",
            "Epoch 70/80\n",
            "84/84 - 43s - loss: 0.5832 - accuracy: 0.8327 - 43s/epoch - 507ms/step\n",
            "Epoch 71/80\n",
            "84/84 - 42s - loss: 0.5691 - accuracy: 0.8369 - 42s/epoch - 501ms/step\n",
            "Epoch 72/80\n",
            "84/84 - 42s - loss: 0.5377 - accuracy: 0.8495 - 42s/epoch - 505ms/step\n",
            "Epoch 73/80\n",
            "84/84 - 42s - loss: 0.5270 - accuracy: 0.8515 - 42s/epoch - 503ms/step\n",
            "Epoch 74/80\n",
            "84/84 - 42s - loss: 0.5085 - accuracy: 0.8579 - 42s/epoch - 504ms/step\n",
            "Epoch 75/80\n",
            "84/84 - 42s - loss: 0.4960 - accuracy: 0.8608 - 42s/epoch - 503ms/step\n",
            "Epoch 76/80\n",
            "84/84 - 42s - loss: 0.4812 - accuracy: 0.8662 - 42s/epoch - 503ms/step\n",
            "Epoch 77/80\n",
            "84/84 - 42s - loss: 0.4667 - accuracy: 0.8708 - 42s/epoch - 504ms/step\n",
            "Epoch 78/80\n",
            "84/84 - 42s - loss: 0.4419 - accuracy: 0.8799 - 42s/epoch - 502ms/step\n",
            "Epoch 79/80\n",
            "84/84 - 42s - loss: 0.4324 - accuracy: 0.8816 - 42s/epoch - 500ms/step\n",
            "Epoch 80/80\n",
            "84/84 - 42s - loss: 0.4165 - accuracy: 0.8870 - 42s/epoch - 504ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcfea42c310>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 문자를 주면 다음 문자를 계속해서 생성\n",
        "def sentence_generation(model, length):\n",
        "  # 문자에 대한 랜덤한 정수 생성\n",
        "  ix = [np.random.randint(vocab_size)]\n",
        "\n",
        "  # 랜덤한 정수로부터 맵핑되는 문자 생성\n",
        "  y_char = [index_to_char[ix[-1]]]\n",
        "  print(ix[-1], '번 문자', y_char[-1], '로 예측을 시작!')\n",
        "\n",
        "  # (1, length, 55) 크기의 x 생성. 즉, LSTM의 입력 시퀀스 생성\n",
        "  x = np.zeros((1, length, vocab_size))\n",
        "\n",
        "  for i in range(length):\n",
        "    # x[0][i][예측한 문자의 인덱스] = 1, 즉, 예측 문자를 다음 입력 시퀀스에 추가\n",
        "    x[0][i][ix[-1]] = 1\n",
        "    print(index_to_char[ix[-1]], end=\"\")\n",
        "    ix = np.argmax(model.predict(x[:, :i+1, :])[0], 1)\n",
        "    y_char.append(index_to_char[ix[-1]])\n",
        "  return ('').join(y_char)"
      ],
      "metadata": {
        "id": "ZJ1LYQR4pX9j"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sentence_generation(model, 100)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvMDIEEvqVvp",
        "outputId": "74805d97-5807-4d7c-8ef0-dafe463f6e5e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 번 문자 4 로 예측을 시작!\n",
            "4 down the rabbit-hole chapter ii.    the pool of tears chapter viii m glowed oo manne my waist dawa4 down the rabbit-hole chapter ii.    the pool of tears chapter viii m glowed oo manne my waist dawal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 문자 단위 RNN으로 텍스트 생성하기\n",
        "### 1) 데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "yw-jxt9Yqdhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "EN8Ad1j0qlSD"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = '''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''\n",
        "\n",
        "# 위에는 저자가 작성한 노래 가사\n",
        "# 위에 텍스트에 존재하는 단락 구분을 없애고 하나의 문자열로 재저장\n",
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        "print(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ2i-cdVquL2",
        "outputId": "422511e7-97fc-4118-e16d-6ad9f7d49686"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복을 제거한 문자 집합 생성\n",
        "char_vocab = sorted(list(set(raw_text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print(\"문자 집합 :\", char_vocab)\n",
        "print(\"문자 집합의 크기 : {}\".format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feAxDiD4rAC_",
        "outputId": "93b64dab-6d75-4194-d2e3-2b676a05eabf"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 : [' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
            "문자 집합의 크기 : 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))    #문자에 고유한 정수 인덱스 부여\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V81vKxlcrN9x",
        "outputId": "6c7645f0-8cb1-476c-f27c-ddc4e962b53f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 시퀀스의 길이가 10이 되도록 데이터 구성\n",
        "# 예측 대상인 문자도 필요하므로 길이가 11이 되도록 데이터 구성\n",
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(raw_text)):\n",
        "  seq = raw_text[i-length:i]    # 길이 11의 문자열을 지속적으로 만든다\n",
        "  sequences.append(seq)\n",
        "print('총 훈련 샘플의 수 : %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIZWGdKqr8Kt",
        "outputId": "7945bc4a-6a6c-422e-eec1-dbc77c46e4f9"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 훈련 샘플의 수 : 426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개만 출력\n",
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LqBz9Q3sVjM",
        "outputId": "5478d9c8-04f5-4112-9533-74387ab4832b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I get on wi',\n",
              " ' get on wit',\n",
              " 'get on with',\n",
              " 'et on with ',\n",
              " 't on with l',\n",
              " ' on with li',\n",
              " 'on with lif',\n",
              " 'n with life',\n",
              " ' with life ',\n",
              " 'with life a']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# char_to_index(앞에서 만듬)를 사용하여 전체 데이터에 대해서 정수 인코딩을 수행\n",
        "encoded_sequences = []\n",
        "for sequence in sequences:    # 전체 데이터에서 문장 샘플을 1개씩 꺼낸다\n",
        "  encoded_sequence = [char_to_index[char] for char in sequence]    # 문장 샘플에서 각 문자에 대해서 정수 인코딩을 수행\n",
        "  encoded_sequences.append(encoded_sequence)"
      ],
      "metadata": {
        "id": "-ILW7oYBscmv"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩 된 결과가 x에 저장됨. 5개만 출력\n",
        "encoded_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsSsHmDiszAW",
        "outputId": "44cdb875-85b3-42e1-e29f-f166d6002c3d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18],\n",
              " [0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28],\n",
              " [16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17],\n",
              " [14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0],\n",
              " [28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자 분리\n",
        "# 모든 샘플 문장에 대해서 마지막 문자를 분리하여\n",
        "# 마지막 문자가 분리된 샘플은 x_data에 저장, 마지막 문자는 y_data에 저장\n",
        "encoded_sequences = np.array(encoded_sequences)\n",
        "\n",
        "# 맨 마지막 위치의 문자를 분리\n",
        "x_data = encoded_sequences[:, :-1]\n",
        "# 맨 마지막 위치의 문자를 저장\n",
        "y_data = encoded_sequences[:, -1]\n",
        "\n",
        "print(x_data[:5])\n",
        "print(y_data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzG3zXkss7qh",
        "outputId": "6157c043-2cee-4e6b-ff03-a6038cb9f135"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8  0 16 14 28  0 24 23  0 31]\n",
            " [ 0 16 14 28  0 24 23  0 31 18]\n",
            " [16 14 28  0 24 23  0 31 18 28]\n",
            " [14 28  0 24 23  0 31 18 28 17]\n",
            " [28  0 24 23  0 31 18 28 17  0]]\n",
            "[18 28 17  0 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x와 y에 대해서 원-핫 인코딩\n",
        "x_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in x_data]\n",
        "x_data_one_hot = np.array(x_data_one_hot)\n",
        "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)\n",
        "\n",
        "print(x_data_one_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGEWbawWtbne",
        "outputId": "26c065d8-1c13-4ba8-a4eb-be046b7a28b4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(426, 10, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 모델 설계하기"
      ],
      "metadata": {
        "id": "rmqBstEbtyms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "hidden_units = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_units, input_shape=(x_data_one_hot.shape[1], x_data_one_hot.shape[2])))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_data_one_hot, y_data_one_hot, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNSkyK_Vt0P8",
        "outputId": "b08f9197-a5c0-43c0-bcf2-777967e35bb1"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 - 2s - loss: 3.4600 - accuracy: 0.1479 - 2s/epoch - 137ms/step\n",
            "Epoch 2/100\n",
            "14/14 - 0s - loss: 3.3193 - accuracy: 0.1972 - 95ms/epoch - 7ms/step\n",
            "Epoch 3/100\n",
            "14/14 - 0s - loss: 3.0778 - accuracy: 0.1972 - 97ms/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "14/14 - 0s - loss: 3.0087 - accuracy: 0.1972 - 97ms/epoch - 7ms/step\n",
            "Epoch 5/100\n",
            "14/14 - 0s - loss: 2.9702 - accuracy: 0.1972 - 96ms/epoch - 7ms/step\n",
            "Epoch 6/100\n",
            "14/14 - 0s - loss: 2.9456 - accuracy: 0.1972 - 94ms/epoch - 7ms/step\n",
            "Epoch 7/100\n",
            "14/14 - 0s - loss: 2.9266 - accuracy: 0.1972 - 96ms/epoch - 7ms/step\n",
            "Epoch 8/100\n",
            "14/14 - 0s - loss: 2.9161 - accuracy: 0.1972 - 98ms/epoch - 7ms/step\n",
            "Epoch 9/100\n",
            "14/14 - 0s - loss: 2.8987 - accuracy: 0.1972 - 109ms/epoch - 8ms/step\n",
            "Epoch 10/100\n",
            "14/14 - 0s - loss: 2.8828 - accuracy: 0.1972 - 98ms/epoch - 7ms/step\n",
            "Epoch 11/100\n",
            "14/14 - 0s - loss: 2.8646 - accuracy: 0.1972 - 101ms/epoch - 7ms/step\n",
            "Epoch 12/100\n",
            "14/14 - 0s - loss: 2.8502 - accuracy: 0.1972 - 96ms/epoch - 7ms/step\n",
            "Epoch 13/100\n",
            "14/14 - 0s - loss: 2.8259 - accuracy: 0.1972 - 105ms/epoch - 8ms/step\n",
            "Epoch 14/100\n",
            "14/14 - 0s - loss: 2.8012 - accuracy: 0.1972 - 104ms/epoch - 7ms/step\n",
            "Epoch 15/100\n",
            "14/14 - 0s - loss: 2.7776 - accuracy: 0.1995 - 97ms/epoch - 7ms/step\n",
            "Epoch 16/100\n",
            "14/14 - 0s - loss: 2.7594 - accuracy: 0.2113 - 102ms/epoch - 7ms/step\n",
            "Epoch 17/100\n",
            "14/14 - 0s - loss: 2.7273 - accuracy: 0.1972 - 99ms/epoch - 7ms/step\n",
            "Epoch 18/100\n",
            "14/14 - 0s - loss: 2.6826 - accuracy: 0.2441 - 103ms/epoch - 7ms/step\n",
            "Epoch 19/100\n",
            "14/14 - 0s - loss: 2.6528 - accuracy: 0.2324 - 103ms/epoch - 7ms/step\n",
            "Epoch 20/100\n",
            "14/14 - 0s - loss: 2.6153 - accuracy: 0.2418 - 103ms/epoch - 7ms/step\n",
            "Epoch 21/100\n",
            "14/14 - 0s - loss: 2.5741 - accuracy: 0.2746 - 100ms/epoch - 7ms/step\n",
            "Epoch 22/100\n",
            "14/14 - 0s - loss: 2.5353 - accuracy: 0.2723 - 96ms/epoch - 7ms/step\n",
            "Epoch 23/100\n",
            "14/14 - 0s - loss: 2.4776 - accuracy: 0.2958 - 109ms/epoch - 8ms/step\n",
            "Epoch 24/100\n",
            "14/14 - 0s - loss: 2.4376 - accuracy: 0.3146 - 102ms/epoch - 7ms/step\n",
            "Epoch 25/100\n",
            "14/14 - 0s - loss: 2.3862 - accuracy: 0.3192 - 95ms/epoch - 7ms/step\n",
            "Epoch 26/100\n",
            "14/14 - 0s - loss: 2.3589 - accuracy: 0.3192 - 101ms/epoch - 7ms/step\n",
            "Epoch 27/100\n",
            "14/14 - 0s - loss: 2.3205 - accuracy: 0.3239 - 109ms/epoch - 8ms/step\n",
            "Epoch 28/100\n",
            "14/14 - 0s - loss: 2.2644 - accuracy: 0.3615 - 107ms/epoch - 8ms/step\n",
            "Epoch 29/100\n",
            "14/14 - 0s - loss: 2.2218 - accuracy: 0.3662 - 97ms/epoch - 7ms/step\n",
            "Epoch 30/100\n",
            "14/14 - 0s - loss: 2.1895 - accuracy: 0.3991 - 100ms/epoch - 7ms/step\n",
            "Epoch 31/100\n",
            "14/14 - 0s - loss: 2.1157 - accuracy: 0.3897 - 102ms/epoch - 7ms/step\n",
            "Epoch 32/100\n",
            "14/14 - 0s - loss: 2.0721 - accuracy: 0.4108 - 97ms/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "14/14 - 0s - loss: 2.0315 - accuracy: 0.4178 - 95ms/epoch - 7ms/step\n",
            "Epoch 34/100\n",
            "14/14 - 0s - loss: 1.9927 - accuracy: 0.4390 - 100ms/epoch - 7ms/step\n",
            "Epoch 35/100\n",
            "14/14 - 0s - loss: 1.9460 - accuracy: 0.4601 - 94ms/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "14/14 - 0s - loss: 1.8872 - accuracy: 0.4601 - 104ms/epoch - 7ms/step\n",
            "Epoch 37/100\n",
            "14/14 - 0s - loss: 1.8484 - accuracy: 0.4930 - 97ms/epoch - 7ms/step\n",
            "Epoch 38/100\n",
            "14/14 - 0s - loss: 1.8058 - accuracy: 0.5188 - 113ms/epoch - 8ms/step\n",
            "Epoch 39/100\n",
            "14/14 - 0s - loss: 1.7445 - accuracy: 0.5305 - 95ms/epoch - 7ms/step\n",
            "Epoch 40/100\n",
            "14/14 - 0s - loss: 1.7158 - accuracy: 0.5469 - 92ms/epoch - 7ms/step\n",
            "Epoch 41/100\n",
            "14/14 - 0s - loss: 1.6760 - accuracy: 0.5516 - 97ms/epoch - 7ms/step\n",
            "Epoch 42/100\n",
            "14/14 - 0s - loss: 1.6397 - accuracy: 0.5446 - 94ms/epoch - 7ms/step\n",
            "Epoch 43/100\n",
            "14/14 - 0s - loss: 1.5982 - accuracy: 0.5869 - 101ms/epoch - 7ms/step\n",
            "Epoch 44/100\n",
            "14/14 - 0s - loss: 1.5805 - accuracy: 0.5775 - 95ms/epoch - 7ms/step\n",
            "Epoch 45/100\n",
            "14/14 - 0s - loss: 1.5201 - accuracy: 0.6009 - 93ms/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "14/14 - 0s - loss: 1.4956 - accuracy: 0.6291 - 98ms/epoch - 7ms/step\n",
            "Epoch 47/100\n",
            "14/14 - 0s - loss: 1.4338 - accuracy: 0.6479 - 96ms/epoch - 7ms/step\n",
            "Epoch 48/100\n",
            "14/14 - 0s - loss: 1.4262 - accuracy: 0.6338 - 110ms/epoch - 8ms/step\n",
            "Epoch 49/100\n",
            "14/14 - 0s - loss: 1.3908 - accuracy: 0.6338 - 99ms/epoch - 7ms/step\n",
            "Epoch 50/100\n",
            "14/14 - 0s - loss: 1.3362 - accuracy: 0.6549 - 101ms/epoch - 7ms/step\n",
            "Epoch 51/100\n",
            "14/14 - 0s - loss: 1.3145 - accuracy: 0.6761 - 102ms/epoch - 7ms/step\n",
            "Epoch 52/100\n",
            "14/14 - 0s - loss: 1.2672 - accuracy: 0.6925 - 105ms/epoch - 7ms/step\n",
            "Epoch 53/100\n",
            "14/14 - 0s - loss: 1.2269 - accuracy: 0.6948 - 100ms/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "14/14 - 0s - loss: 1.1998 - accuracy: 0.7066 - 99ms/epoch - 7ms/step\n",
            "Epoch 55/100\n",
            "14/14 - 0s - loss: 1.1546 - accuracy: 0.7160 - 100ms/epoch - 7ms/step\n",
            "Epoch 56/100\n",
            "14/14 - 0s - loss: 1.1326 - accuracy: 0.7207 - 101ms/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "14/14 - 0s - loss: 1.1105 - accuracy: 0.7418 - 118ms/epoch - 8ms/step\n",
            "Epoch 58/100\n",
            "14/14 - 0s - loss: 1.0868 - accuracy: 0.7207 - 104ms/epoch - 7ms/step\n",
            "Epoch 59/100\n",
            "14/14 - 0s - loss: 1.0428 - accuracy: 0.7535 - 102ms/epoch - 7ms/step\n",
            "Epoch 60/100\n",
            "14/14 - 0s - loss: 1.0106 - accuracy: 0.7559 - 102ms/epoch - 7ms/step\n",
            "Epoch 61/100\n",
            "14/14 - 0s - loss: 0.9968 - accuracy: 0.7441 - 96ms/epoch - 7ms/step\n",
            "Epoch 62/100\n",
            "14/14 - 0s - loss: 0.9586 - accuracy: 0.7653 - 100ms/epoch - 7ms/step\n",
            "Epoch 63/100\n",
            "14/14 - 0s - loss: 0.9220 - accuracy: 0.7840 - 93ms/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "14/14 - 0s - loss: 0.8931 - accuracy: 0.7958 - 101ms/epoch - 7ms/step\n",
            "Epoch 65/100\n",
            "14/14 - 0s - loss: 0.8691 - accuracy: 0.8052 - 103ms/epoch - 7ms/step\n",
            "Epoch 66/100\n",
            "14/14 - 0s - loss: 0.8323 - accuracy: 0.8263 - 101ms/epoch - 7ms/step\n",
            "Epoch 67/100\n",
            "14/14 - 0s - loss: 0.8128 - accuracy: 0.8451 - 105ms/epoch - 8ms/step\n",
            "Epoch 68/100\n",
            "14/14 - 0s - loss: 0.7728 - accuracy: 0.8286 - 100ms/epoch - 7ms/step\n",
            "Epoch 69/100\n",
            "14/14 - 0s - loss: 0.7486 - accuracy: 0.8521 - 100ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "14/14 - 0s - loss: 0.7354 - accuracy: 0.8427 - 101ms/epoch - 7ms/step\n",
            "Epoch 71/100\n",
            "14/14 - 0s - loss: 0.7204 - accuracy: 0.8521 - 105ms/epoch - 8ms/step\n",
            "Epoch 72/100\n",
            "14/14 - 0s - loss: 0.7050 - accuracy: 0.8474 - 103ms/epoch - 7ms/step\n",
            "Epoch 73/100\n",
            "14/14 - 0s - loss: 0.6877 - accuracy: 0.8709 - 100ms/epoch - 7ms/step\n",
            "Epoch 74/100\n",
            "14/14 - 0s - loss: 0.6544 - accuracy: 0.8732 - 104ms/epoch - 7ms/step\n",
            "Epoch 75/100\n",
            "14/14 - 0s - loss: 0.6400 - accuracy: 0.8897 - 101ms/epoch - 7ms/step\n",
            "Epoch 76/100\n",
            "14/14 - 0s - loss: 0.6190 - accuracy: 0.8850 - 113ms/epoch - 8ms/step\n",
            "Epoch 77/100\n",
            "14/14 - 0s - loss: 0.5863 - accuracy: 0.8944 - 102ms/epoch - 7ms/step\n",
            "Epoch 78/100\n",
            "14/14 - 0s - loss: 0.5703 - accuracy: 0.9108 - 104ms/epoch - 7ms/step\n",
            "Epoch 79/100\n",
            "14/14 - 0s - loss: 0.5682 - accuracy: 0.9108 - 99ms/epoch - 7ms/step\n",
            "Epoch 80/100\n",
            "14/14 - 0s - loss: 0.5290 - accuracy: 0.9202 - 100ms/epoch - 7ms/step\n",
            "Epoch 81/100\n",
            "14/14 - 0s - loss: 0.5099 - accuracy: 0.9272 - 99ms/epoch - 7ms/step\n",
            "Epoch 82/100\n",
            "14/14 - 0s - loss: 0.5038 - accuracy: 0.9366 - 112ms/epoch - 8ms/step\n",
            "Epoch 83/100\n",
            "14/14 - 0s - loss: 0.4952 - accuracy: 0.9413 - 104ms/epoch - 7ms/step\n",
            "Epoch 84/100\n",
            "14/14 - 0s - loss: 0.4718 - accuracy: 0.9272 - 104ms/epoch - 7ms/step\n",
            "Epoch 85/100\n",
            "14/14 - 0s - loss: 0.4480 - accuracy: 0.9437 - 98ms/epoch - 7ms/step\n",
            "Epoch 86/100\n",
            "14/14 - 0s - loss: 0.4318 - accuracy: 0.9507 - 121ms/epoch - 9ms/step\n",
            "Epoch 87/100\n",
            "14/14 - 0s - loss: 0.4233 - accuracy: 0.9507 - 96ms/epoch - 7ms/step\n",
            "Epoch 88/100\n",
            "14/14 - 0s - loss: 0.4140 - accuracy: 0.9460 - 101ms/epoch - 7ms/step\n",
            "Epoch 89/100\n",
            "14/14 - 0s - loss: 0.3985 - accuracy: 0.9507 - 100ms/epoch - 7ms/step\n",
            "Epoch 90/100\n",
            "14/14 - 0s - loss: 0.3843 - accuracy: 0.9624 - 103ms/epoch - 7ms/step\n",
            "Epoch 91/100\n",
            "14/14 - 0s - loss: 0.3577 - accuracy: 0.9648 - 97ms/epoch - 7ms/step\n",
            "Epoch 92/100\n",
            "14/14 - 0s - loss: 0.3497 - accuracy: 0.9718 - 101ms/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "14/14 - 0s - loss: 0.3385 - accuracy: 0.9648 - 106ms/epoch - 8ms/step\n",
            "Epoch 94/100\n",
            "14/14 - 0s - loss: 0.3297 - accuracy: 0.9648 - 106ms/epoch - 8ms/step\n",
            "Epoch 95/100\n",
            "14/14 - 0s - loss: 0.3232 - accuracy: 0.9695 - 108ms/epoch - 8ms/step\n",
            "Epoch 96/100\n",
            "14/14 - 0s - loss: 0.3092 - accuracy: 0.9671 - 100ms/epoch - 7ms/step\n",
            "Epoch 97/100\n",
            "14/14 - 0s - loss: 0.2993 - accuracy: 0.9695 - 106ms/epoch - 8ms/step\n",
            "Epoch 98/100\n",
            "14/14 - 0s - loss: 0.2881 - accuracy: 0.9695 - 99ms/epoch - 7ms/step\n",
            "Epoch 99/100\n",
            "14/14 - 0s - loss: 0.2793 - accuracy: 0.9718 - 101ms/epoch - 7ms/step\n",
            "Epoch 100/100\n",
            "14/14 - 0s - loss: 0.2803 - accuracy: 0.9765 - 101ms/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcfe9414bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장을 생성하는 함수\n",
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "  # 초기 시퀀스\n",
        "  init_text = seed_text\n",
        "  sentence = ''\n",
        "\n",
        "  #다음 문자 예측은 총 n번만 반복\n",
        "  for _ in range(n):\n",
        "    encoded = [char_to_index[char] for char in seed_text]  # 현재 시퀀스에 대한 정수 인코딩\n",
        "    encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre')  # 데이터에 대한 패딩\n",
        "    encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
        "\n",
        "    # 입력한 x(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 문자)를 result에 저장\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis=1)\n",
        "\n",
        "    for char, index in char_to_index.items():\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    # 현재 시퀀스 + 예측 문자를 현재 시퀀스로 변경\n",
        "    seed_text = seed_text + char\n",
        "\n",
        "    # 예측 문자를 문장에 저장\n",
        "    sentence = sentence + char\n",
        "\n",
        "  # n번의 다음 문자 예측이 끝나면 최종 완성된 문장을 리턴\n",
        "  sentence = init_text + sentence\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "FoaGrlBEujDw"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO2y6pt0veO3",
        "outputId": "9cb264f2-6522-4f35-a64b-0367e5c00229"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I get on with life as a programmer, I like to hang out with prorrammiug I ndndt tayll...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y_rThuwV36Hx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}