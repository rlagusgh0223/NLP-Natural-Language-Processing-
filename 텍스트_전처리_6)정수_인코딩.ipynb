{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "텍스트 전처리 - 6)정수 인코딩",
      "provenance": [],
      "authorship_tag": "ABX9TyPX3BAqg4PSEBT4husCUd+F"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 정수 인코딩\n",
        "1) dictionary 사용하기"
      ],
      "metadata": {
        "id": "gGNk79oN7TJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w-w_yRJ-vbGz"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "metadata": {
        "id": "tV1c3r3F7fyx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래 두 문장 없으면 안된다\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 문장 토큰화\n",
        "sentences = sent_tokenize(raw_text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgXWyvuy7mO5",
        "outputId": "f85af7d1-4c5f-4117-b532-a5d62a45e759"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래 두 문장 없으면 동작 안한다\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "vocab = {}\n",
        "preprocessed_sentences = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for sentence in sentences:\n",
        "  # 단어 토큰화\n",
        "  tokenized_sentence = word_tokenize(sentence)\n",
        "  result = []\n",
        "\n",
        "  for word in tokenized_sentence:\n",
        "    word = word.lower()    # 모든 단어를 소문자화하여 단어의 개수를 줄인다\n",
        "    if word not in stop_words:    # 단어 토큰화 된 결과에 대해서 불용어를 제거한다\n",
        "      if len(word) > 2:    # 단어 길이가 2 이하인 경우에 대하여 추가로 단어를 제거한다\n",
        "        result.append(word)\n",
        "        if word not in vocab:\n",
        "          vocab[word] = 0\n",
        "        vocab[word] += 1\n",
        "  preprocessed_sentences.append(result)\n",
        "print(preprocessed_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC0jUf347uD6",
        "outputId": "2173bbbf-b52a-443d-bac7-64e10bf01804"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab에 기록된 각 단어에 대한 빈도수 출력\n",
        "print(\"단어 집합 :\", vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjgF9ohC8x_i",
        "outputId": "bb204cec-0dfd-4590-ecb7-2a10331e9ac6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'barber'라는 단어의 빈도수 출력\n",
        "print(vocab['barber'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIs9F3hY9B_S",
        "outputId": "6d5dbae0-d2a4-48fc-c8c4-f176d78dd79a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도수가 높은 순서대로 정렬\n",
        "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
        "print(vocab_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrf_RRoE9MEy",
        "outputId": "9f2db23d-e714-498e-d11b-aeab855a2722"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 높은 빈도수를 가진 단어일수록 낮은 정수를 부여함(1부터)\n",
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab_sorted:\n",
        "  if frequency > 1:    # 빈도수가 작은 단어는 제외\n",
        "    i += 1\n",
        "    word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXvC3zb09V_A",
        "outputId": "a427f39f-f751-49d7-b642-25531bca4489"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 5개 단어만 사용\n",
        "vocab_size = 5\n",
        "\n",
        "# 인덱스가 5 초과인 단어 제거\n",
        "words_frequency = [word for word, index in word_to_index.items() if index >= vocab_size + 1]\n",
        "\n",
        "# 해당 단어에 대한 인덱스 정보를 삭제\n",
        "for w in words_frequency:\n",
        "  del word_to_index[w]\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVy3U6w69zL8",
        "outputId": "412a059e-f214-423c-cdee-a45f92ae81d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['OOV'] = len(word_to_index) + 1    # OOV란 단어를 추가하고, 단어 집합에 없는 단어들은 그 인덱스에 인코딩\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF25-GVs-3zA",
        "outputId": "6535ba7a-233c-469e-962b-4186966627fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'OOV': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word_to_index를 사용하여 sentences의 모든 단어들을 맵핑되는 정수로 인코딩\n",
        "encoded_sentences = []\n",
        "for sentence in preprocessed_sentences:\n",
        "  encoded_sentence = []\n",
        "  for word in sentence:\n",
        "    try:\n",
        "      # 단어 집합에 있는 단어라면 해당 언어의 정수를 리턴\n",
        "      encoded_sentence.append(word_to_index[word])\n",
        "    except KeyError:\n",
        "      # 만약 단어 집합에 없는 단어라면 'OOV'의 정수를 리턴\n",
        "      encoded_sentence.append(word_to_index['OOV'])\n",
        "  encoded_sentences.append(encoded_sentence)\n",
        "print(encoded_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVeD-3LL_VN5",
        "outputId": "9d4c9b36-88ae-47fa-8f76-e770aa863170"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Counter 사용하기"
      ],
      "metadata": {
        "id": "9LE4WqPvAIWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(preprocessed_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7o17JhLADik",
        "outputId": "f161f764-a4ec-468a-dda3-9082f9a27b36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 집합을 만들기 위해 sentences에서 문장의 경계인 [,]를 제거하고 단어들을 하나의 리스트로 만듬\n",
        "# words = np.hstack(preprocessed_sentences)으로도 수행 가능\n",
        "all_words_list = sum(preprocessed_sentences, [])\n",
        "print(all_words_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7MRjhtJAOfU",
        "outputId": "ac44cd0e-25b3-47a3-9835-9d62f5b3d8e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이썬의 Counter 모듈을 이용하여 단어의 빈도수 카운트(중복 제거)\n",
        "vocab = Counter(all_words_list)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6qGrhocAkAH",
        "outputId": "84fe3d6b-ff24-4713-a479-f3f965fada88"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab['barber'])    # 'barber'라는 단어의 빈도수 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1onsvEE_Ax_5",
        "outputId": "361f0985-1ac9-4649-8e92-8bb362e4d30f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# most_common()는 상위 빈도수를 가진 주어진 수의 단어만을 리턴\n",
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size)    # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnOMmVaUA5Cy",
        "outputId": "82277b0b-da72-4937-bb2f-3cf12e918eb5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 높은 빈도수를 가진 단어일수록 낮은 정수 인덱스 부여\n",
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab:\n",
        "  i += 1\n",
        "  word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMlPDt-jBJ-7",
        "outputId": "3ef29286-fd13-458d-df94-c6807c562af4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) NLTK의 FreqDist 사용하기"
      ],
      "metadata": {
        "id": "kprcber4BX26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist    # 빈도수 계산 도구\n",
        "import numpy as np\n",
        "\n",
        "# np.hsatck으로 문장 구분을 제거\n",
        "vocab = FreqDist(np.hstack(preprocessed_sentences))"
      ],
      "metadata": {
        "id": "Gjt1-L9bBV97"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab['barber'])    # 'barber'라는 단어의 빈도수 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAcVDHgQBnsh",
        "outputId": "353a7423-9fc1-492d-f789-ecbf14ae85ba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# most_common()는 상위 빈도수를 가진 주어진 수의 단어만을 리턴\n",
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size)    # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp37xJvDBtfz",
        "outputId": "731fe8c9-b0ba-4a2c-f215-27e65f239d1f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 높은 빈도수를 가진 단어일수록 낮은 정수 인덱스 부여\n",
        "word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtt8pkjsB8tj",
        "outputId": "6dfee85d-31c8-465c-effe-9c4f93963682"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) enumerate 이해하기"
      ],
      "metadata": {
        "id": "KyEc5AIcCOkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 순서가 있는 자료형을 입력받아 인덱스를 순차적으로 함께 리턴\n",
        "test_input = ['a', 'b', 'c', 'd', 'e']\n",
        "for index, value in enumerate(test_input):    # 입력의 순서대로 0부터 인덱스를 부여함\n",
        "  print('value : {}, index : {}'.format(value, index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx5_yvZfCKEG",
        "outputId": "87d00f45-e618-44f2-d5f7-7440a8482310"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value : a, index : 0\n",
            "value : b, index : 1\n",
            "value : c, index : 2\n",
            "value : d, index : 3\n",
            "value : e, index : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 케라스의 텍스트 전처리"
      ],
      "metadata": {
        "id": "agz3ulZcDxid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "IS0S6LonDqWI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
      ],
      "metadata": {
        "id": "uSl-vnf7EBnu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "# fit_on_texts() 안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "jq56MD7lEFXG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyMTOU4sERIV",
        "outputId": "fa26ef2c-6d3e-46da-88b0-a84fa6f6143e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_counts)    # 각 단어가 몇개 였는지"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39mGLbofEX-9",
        "outputId": "2b859f71-87ea-49bc-9b83-2523efda21ba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# texts_to_sequences()는 입력으로 들어온 코퍼스에 대해서 각 단어를 이미 정해진 인덱스로 변환\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w92frhCpEhq3",
        "outputId": "d71771a7-2c5b-4345-aca3-1f855ad6c088"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 케라스는 tokenizer = Tokenizer(num_words=숫자)와 같은 방법으로 빈도수가 높은 상위 몇개의 단어만 사용하겠다고 지정 가능\n",
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 1)    # 상위 5개 단어만 사용(num_words는 0부터 카운트한다)\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "T5joKgu2Exmx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-QDKFK4Fdk4",
        "outputId": "fc69e398-e516-412e-b4c1-973959640fea"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfbN4q19Fv54",
        "outputId": "2358c3b8-ea38-41de-dcb4-6edbd9fcbfa7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실제 적용은 texts_to_sequences를 사용할 때 적용\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyl4tTtAF2EQ",
        "outputId": "d1b900ab-bed7-4c3f-a1b0-99c283a6bc1d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word_index와 word_counts에서도 지정된 num_words만큼의 단어만 남기고 싶다면\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)\n",
        "\n",
        "vocab_size = 5\n",
        "words_frequency = [word for word, index in tokenizer.word_index.items() if index >= vocab_size + 1]\n",
        "\n",
        "# 인덱스가 5 초과인 단어 제거\n",
        "for word in words_frequency:\n",
        "  del tokenizer.word_index[word]    # 해당 단어에 대한 인덱스 정보를 삭제\n",
        "  del tokenizer.word_counts[word]    # 해당 단어에 대한 카운트 정보를 삭제\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5NBElVeGAzZ",
        "outputId": "d2e079ff-8aaa-436f-da4f-ef4697137072"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
            "OrderedDict([('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4)])\n",
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 케라스 토크나이저는 기본적으로 단어 집합에 없는 단어인 OOV에 대해서는 단어를 정수로 바꾸는 과정에서\n",
        "# 아예 단어를 제거한다\n",
        "# 만약 OOV로 간주하여 보존하고 싶다면 oov_token 사용\n",
        "\n",
        "# 숫자 0과 oov를 고려해서 단어 집합의 크기는 +2\n",
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "vEeKfestG2yX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 만약 oov_token을 사용하기로 했다면 케라스 토크나이저는 기본적으로 'OOV'의 인덱스를 1로 한다\n",
        "print(\"단어 OOV의 인덱스 : {}\".format(tokenizer.word_index['OOV']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2bbZEOlHWJp",
        "outputId": "ac0430fc-a36e-417f-8dfb-45a2a4d40b66"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 OOV의 인덱스 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코퍼스에 대해서 정수 인코딩 진행\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WdpCpfWHkaM",
        "outputId": "ea2818bd-b20b-429d-8405-4b1456a4cedc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DX4GoRm2Hs_E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}